[
["index.html", "R for Pogressive Campaigns Chapter 1 Preface 1.1 Getting Help 1.2 Infrastructure overview", " R for Pogressive Campaigns Josiah Parry 2019-07-29 Chapter 1 Preface As the 2020 Presidential election looms nearer and nearer. It is important that every campaign is keeping an eye on their field performance. In 2008, the Obama campaign revolutionized the use of data in political campaigns. Since then, data teams have expanded and grown in size, capacity, and complexity. This short bookdown project is intended to illustrate how data can be used in campaigns through the statistical programming language R. This is a collection of small “recipes” that I have created that are intended to aid data teams in leveragng R. As the Data Director for NextGen American New Hampshire team during the 2018 midterm elections, I learned a lot about the ways that data was and wasn’t being leveraged in progressive politics. This is my attempt to democratize (pun heavily intended) data analytic skills for progressive campaigns. I write this with a few assumptions. These being that you have at least a fundamental background in R—if this is not the case, please work through the first few chapters of R for Data Science. I also assume that you and your team are using VAN (Voter Activation Network); potentially using Civis Analytics for hosting, scheduling, and exporting your data; and are utilizing Google Sheets to some extent in your work. Note that none of the above has to be true for these examples to be useful for you and your team. 1.1 Getting Help If you find yourself struggling with any of these exercises or handling data for your own use-case there are a number of ways to seek help. If you have code specific issues, you can always head over to stackoverflow. The RStudio Community page is another great resource. Also, do not hesitate to reach out to me direcly via Twitter (@josiahparry), my DMs are open. 1.2 Infrastructure overview This will be a brief introduction to the tools your organization might be using. “If it is not in VAN, it does not exist” - Every VAN Admin NGP VAN is the Voter Activation Network. VAN is the location where all voter interactions live. VAN is our database for voter outreach.When contact is made with a potential voter that is entered in VAN. There are many common ways that this data is recorded. Crowd canvassing—i.e. collecting pledge cards, petitioon sign ups. Door-to-door canvassing—i.e. knocking on doors and having direct conversations with voters. This is sometimes referred to “knocking doors”. Two other common types of voter outreach is phone banking and text banking. What is Civis? Civis analytics is a company that creates a data sciecne platforms which is used by many progressive campaigns. They provide secure cloud based solution for data warehousing, analysis, and workflow automation, among others. It is common for many campaigns to have daily exports from VAN into Civis. This provides data directors and data managers the ability to programmatically analyse VAN data. Since data are avaialble in a database, they can be queried using SQL. SQL scripts are written to create aaggregated data. A lot of the power of this comes from the ability to create workflows in Civis. The output of SQL scripts can be exported to a Google Sheet which is much more accessible for the less technically inclined. This also is great for creating shareable sheets-based reporting. The workflow: This guide/book will try to replicate this workflow as best as possible. "],
["calculating-ptg.html", "Chapter 2 calculating PTG 2.1 Exercise", " Chapter 2 calculating PTG 2.0.1 Goal: Demonstrate how to take raw canvassing data and calculate a PTG. One of the first reports that a data team is asked to create is the Percent to Goal (hereforth referred to as PTG). A PTG report is intended to illustrate numerically how well a field team is performing. After all, the strength of a campaign comes down to two things in particular: 1) how well your team can mobilize voters on the ground, and 2) reaching potential voters through digital media. This report will focus on field performance. Field work is primarily focused on canvassing. There are two types of canvassing that we care about. Crowd canvassing: walking around and engaging voters in the public space (i.e. talking to people at a farmers market) Door-to-door canvassing: knocking directly on voters’ doors to discuss candidates, polling locations, etc. This article from Masterclass does a solid job of describing canvassing. This chapter will walk you through analyzing crowd canvassing data. Crowd canvassing is usually done through the use of pledge cards. Pledge cards explicitly ask voters to commit to voting, their reasons for voting for a specific candidates (usually issue based to gather further targeting information), and often have an optional field to indicate whether or not they will volunteer. Additionally, field territory is often split up into regions. Each region has their own goals to meet (usually based on voter population) for the number of people pledged to vote and volunteer. This report will see how far along each region is by week to their goal. The packages that will be used in this chapter are: readr: Reading data (imported in the tidyverse) dplyr: Manipulating datta (imported in the tidyverse) ggplot2: Visualizing data (imported in the tidyverse) lubridate: Managing dates Skills that will be covered: Reading data Joining tables Aggregating data Visualizing data This assumes that you have an understanding of dplyr and ggplot2. In this exercise we will use three datasets (located in the data folder). canvassing_results.csv: canvassing results from January to March van_turf_lookup.csv: dataset containing the region codes for each van user goals.csv: dataset containing the weekly pledge card goal Steps: Read in canvassing results Read in turf code look up table Create new week variable Aggregate on the weekly level Read in goals Calculate PTG 2.1 Exercise library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.1.1 ✔ purrr 0.3.2 ## ✔ tibble 2.1.3 ✔ dplyr 0.8.3 ## ✔ tidyr 0.8.3 ✔ stringr 1.4.0 ## ✔ readr 1.3.1 ✔ forcats 0.4.0 ## ── Conflicts ────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ lubridate::as.difftime() masks base::as.difftime() ## ✖ lubridate::date() masks base::date() ## ✖ dplyr::filter() masks stats::filter() ## ✖ lubridate::intersect() masks base::intersect() ## ✖ dplyr::lag() masks stats::lag() ## ✖ lubridate::setdiff() masks base::setdiff() ## ✖ lubridate::union() masks base::union() library(lubridate) canvass &lt;- read_csv(&quot;data/canvassing_results.csv&quot;) ## Parsed with column specification: ## cols( ## van_id = col_double(), ## date = col_date(format = &quot;&quot;), ## vol_yes = col_double() ## ) canvass ## # A tibble: 6,671 x 3 ## van_id date vol_yes ## &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; ## 1 1 2019-03-15 1 ## 2 2 2019-01-30 1 ## 3 3 2019-02-27 0 ## 4 4 2019-02-21 0 ## 5 5 2019-01-13 0 ## 6 6 2019-01-29 0 ## 7 7 2019-01-07 0 ## 8 8 2019-02-15 0 ## 9 9 2019-01-30 0 ## 10 10 2019-03-06 0 ## # … with 6,661 more rows I always briefly inspect my data using the count() function. Let’s count the number of individuals who marked volunteer yes. count(canvass, vol_yes) ## # A tibble: 2 x 2 ## vol_yes n ## &lt;dbl&gt; &lt;int&gt; ## 1 0 4617 ## 2 1 2054 That is a lot of volunteers! They will go into the volunter recruitment and management pipeline and hopefully convert into some volunteer shifts. But which region are these potential volunteers in? To figure this out we will have to read in the van_turf_lookup.csv dataset. turf_lookup &lt;- read_csv(&quot;data/van_turf_lookup.csv&quot;) ## Parsed with column specification: ## cols( ## van_id = col_double(), ## turf_code = col_character() ## ) turf_lookup ## # A tibble: 6,004 x 2 ## van_id turf_code ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 B ## 2 2 E ## 3 3 E ## 4 4 B ## 5 5 C ## 6 6 E ## 7 7 B ## 8 8 C ## 9 9 D ## 10 10 A ## # … with 5,994 more rows Here we see that there are only two variables, van_id, and turf_code. This is a very common structure in relational data architectures. Because this table and the canvass table both share the van_id column we can merge the who based on this. This is referred to as a “common identifier”. The operation of joining two tables together is called a join. For more on joins and relational data please read chapter 13 of R for Data Science by Hadley Wickham. left_join(canvass, turf_lookup, by = &quot;van_id&quot;) ## # A tibble: 6,671 x 4 ## van_id date vol_yes turf_code ## &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 2019-03-15 1 B ## 2 2 2019-01-30 1 E ## 3 3 2019-02-27 0 E ## 4 4 2019-02-21 0 B ## 5 5 2019-01-13 0 C ## 6 6 2019-01-29 0 E ## 7 7 2019-01-07 0 B ## 8 8 2019-02-15 0 C ## 9 9 2019-01-30 0 D ## 10 10 2019-03-06 0 A ## # … with 6,661 more rows This table provides the turf codes for each van_id, but we still do not have the week that each observation belongs to.We are interested in the weekly pledge card goal so it is important to extract the calendar week from the date field. We will use the function lubridate::week() to do this. Your campaign may use different ways to measure weeks, and this may require some additional finagling on your end. We will pipe the resultant table from the join into a mutate call where we will create this new variable and save it to an object called canvass_clean. canvass_clean &lt;- left_join(canvass, turf_lookup, by = &quot;van_id&quot;) %&gt;% mutate(week = week(date)) canvass_clean ## # A tibble: 6,671 x 5 ## van_id date vol_yes turf_code week ## &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 2019-03-15 1 B 11 ## 2 2 2019-01-30 1 E 5 ## 3 3 2019-02-27 0 E 9 ## 4 4 2019-02-21 0 B 8 ## 5 5 2019-01-13 0 C 2 ## 6 6 2019-01-29 0 E 5 ## 7 7 2019-01-07 0 B 1 ## 8 8 2019-02-15 0 C 7 ## 9 9 2019-01-30 0 D 5 ## 10 10 2019-03-06 0 A 10 ## # … with 6,661 more rows We can use count() again to explore the pledge cards by region and week. We can add unquoted column names as arguments to count() which will be used to group the data. count(canvass_clean, turf_code) ## # A tibble: 6 x 2 ## turf_code n ## &lt;chr&gt; &lt;int&gt; ## 1 A 1137 ## 2 B 1101 ## 3 C 1159 ## 4 D 1114 ## 5 E 1044 ## 6 F 1116 count(canvass_clean, week) ## # A tibble: 11 x 2 ## week n ## &lt;dbl&gt; &lt;int&gt; ## 1 1 651 ## 2 2 629 ## 3 3 552 ## 4 4 637 ## 5 5 607 ## 6 6 614 ## 7 7 617 ## 8 8 643 ## 9 9 641 ## 10 10 640 ## 11 11 440 count(canvass_clean, turf_code, week) ## # A tibble: 66 x 3 ## turf_code week n ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 A 1 114 ## 2 A 2 109 ## 3 A 3 96 ## 4 A 4 121 ## 5 A 5 95 ## 6 A 6 99 ## 7 A 7 78 ## 8 A 8 111 ## 9 A 9 119 ## 10 A 10 119 ## # … with 56 more rows Though these counts (you may be more familiar with the phrase cross-tabs) are extremely useful, we still want to know the number of volunteers pledged. For more control over the aggregate measures, we will use dplyr::group_by() and dplyr::summarise() (for more see chapter 5.6 in R for Data Science). We will create a new table called weekly_canvass which is grouped by turf code and week. This table will have a column for turf_code, week, the number of people pledged to vote n_pledged, and the number of people who indicated they would volunteer vol_yes. weekly_canvass &lt;- canvass_clean %&gt;% group_by(turf_code, week) %&gt;% summarise(n_pledged = n(), vol_yes = sum(vol_yes)) weekly_canvass ## # A tibble: 66 x 4 ## # Groups: turf_code [6] ## turf_code week n_pledged vol_yes ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 A 1 114 41 ## 2 A 2 109 28 ## 3 A 3 96 33 ## 4 A 4 121 34 ## 5 A 5 95 32 ## 6 A 6 99 29 ## 7 A 7 78 28 ## 8 A 8 111 29 ## 9 A 9 119 34 ## 10 A 10 119 27 ## # … with 56 more rows Now that we have our counts of pledges and volunteers by week and turf code we need to compare this to their weekly goal. The weekly goals are in goals.csv. goals &lt;- read_csv(&quot;data/goals.csv&quot;) ## Parsed with column specification: ## cols( ## week = col_double(), ## region = col_character(), ## goal = col_double() ## ) goals ## # A tibble: 312 x 3 ## week region goal ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 A 120 ## 2 1 B 130 ## 3 1 C 70 ## 4 1 D 120 ## 5 1 E 90 ## 6 1 F 130 ## 7 2 A 110 ## 8 2 B 90 ## 9 2 C 130 ## 10 2 D 70 ## # … with 302 more rows Again, this data will need to be joined. What is unique here though is that there is not a single common identifier column. We will need to join on two columns. Namely, region (turf code), and week. Notice that we have mismatched names. To perform a join in this scenario we will need to provide a named vector to the by argument (more on named vectors in chapter 20.4.4 in R for Data Science). The name of the vector element is the column name in the left hand table and the value is the name of the column in the right hand table. In our case, the left hand table is weekly_canvass which has the column name turf_code. The right hand table is goals which has the column name region. To match on this we have to provide the named vector c(&quot;turf_code&quot; = &quot;region). Since the second column we are matching on is week which is present in both tables, this element does not have to be named. Thus the vector we will use is c(&quot;turf_code&quot; = &quot;region&quot;, &quot;week&quot;). left_join(weekly_canvass, goals, by = c(&quot;turf_code&quot; = &quot;region&quot;, &quot;week&quot;)) ## # A tibble: 66 x 5 ## # Groups: turf_code [6] ## turf_code week n_pledged vol_yes goal ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 1 114 41 120 ## 2 A 2 109 28 110 ## 3 A 3 96 33 60 ## 4 A 4 121 34 60 ## 5 A 5 95 32 90 ## 6 A 6 99 29 120 ## 7 A 7 78 28 110 ## 8 A 8 111 29 130 ## 9 A 9 119 34 130 ## 10 A 10 119 27 130 ## # … with 56 more rows With this join we see that we have the goal and the actual number pledged. We’re one step away from calculating the PTG! To calculate the percent we need to divide the actual number by the goal and multiply by 100. We will do this within a mutate call after we join and save this to a new object ptg. ptg &lt;- left_join(weekly_canvass, goals, by = c(&quot;turf_code&quot; = &quot;region&quot;, &quot;week&quot;)) %&gt;% mutate(ptg = (n_pledged / goal) * 100) ptg ## # A tibble: 66 x 6 ## # Groups: turf_code [6] ## turf_code week n_pledged vol_yes goal ptg ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 1 114 41 120 95 ## 2 A 2 109 28 110 99.1 ## 3 A 3 96 33 60 160 ## 4 A 4 121 34 60 202. ## 5 A 5 95 32 90 106. ## 6 A 6 99 29 120 82.5 ## 7 A 7 78 28 110 70.9 ## 8 A 8 111 29 130 85.4 ## 9 A 9 119 34 130 91.5 ## 10 A 10 119 27 130 91.5 ## # … with 56 more rows ptg %&gt;% ggplot(aes(week, ptg, color = turf_code)) + geom_point() + geom_line() + theme_minimal() + facet_wrap(~turf_code) + geom_hline(yintercept = 100, lty = 2) + theme( panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), legend.position = &quot;bottom&quot; ) + labs(title = &quot;PTG by Turf Code&quot;, x = &quot;Week&quot;, y = &quot;%&quot;) While having a table and chart for weekly PTG is extremely useful, it is important to provide a PTG metric for the entire program. To do this we will need to calculate an aggregate measure from the goals table and join this to an aggregated canvass table. We will start by aggregating the goals and creating a total_goals object. Note that in the code chunk below I rename the region column in the group_by() statement this will be useful in the future so we can avoid having to use a named vector in our join. total_goals &lt;- goals %&gt;% group_by(turf_code = region) %&gt;% summarise(goal = sum(goal)) total_goals ## # A tibble: 6 x 2 ## turf_code goal ## &lt;chr&gt; &lt;dbl&gt; ## 1 A 4390 ## 2 B 4530 ## 3 C 4470 ## 4 D 4350 ## 5 E 4640 ## 6 F 4720 Now that we have total_goals we need to know the total number of pledges each region has gathered. We will use the existing canvass_clean object and count the total number or pledges using count(). total_pledges &lt;- count(canvass_clean, turf_code) total_pledges ## # A tibble: 6 x 2 ## turf_code n ## &lt;chr&gt; &lt;int&gt; ## 1 A 1137 ## 2 B 1101 ## 3 C 1159 ## 4 D 1114 ## 5 E 1044 ## 6 F 1116 Now we can join these two tables together and calculate a program wide PTG. total_ptg &lt;- inner_join(total_pledges, total_goals, by = &quot;turf_code&quot;) %&gt;% mutate(ptg = n / goal * 100) total_ptg ## # A tibble: 6 x 4 ## turf_code n goal ptg ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 1137 4390 25.9 ## 2 B 1101 4530 24.3 ## 3 C 1159 4470 25.9 ## 4 D 1114 4350 25.6 ## 5 E 1044 4640 22.5 ## 6 F 1116 4720 23.6 Everyone loves a bar chart to visually understand their data. total_ptg %&gt;% mutate(turf_code = fct_rev(turf_code)) %&gt;% ggplot(aes(turf_code, ptg)) + geom_col() + geom_hline(yintercept = 100, lty = 2) + coord_flip() + labs(title = &quot;Cumulative PTG&quot;) + theme_minimal() + theme( panel.grid.major.x = element_blank() ) To Do: Turn into a report turn into parameterized report emailing with gmailr hosting and scheduling with connect "],
["reporting-googlesheets.html", "Chapter 3 reporting-googlesheets", " Chapter 3 reporting-googlesheets Goal: Create a daily percent to goal report As described previously, a common practice is to export aggregated code from Civis into a Google Sheet. In this section we will work with Google Sheets to create a report that can be used to schedule automatic reporting. To use the googlesheets package you must first install it (install.packages(&quot;googlesheets&quot;)). To load a spreadsheet use the gs_title() or gs_url() functions. The former takes the name of the sheet and the latter uses the url of it. Once this line is ran Google will open and require you to authenticate. This will create .httr-oath file in your working directory. This contains your authorization token which will be used later for automating this workflow. library(googlesheets) # register the sheet sheet &lt;- gs_url(&quot;https://docs.google.com/spreadsheets/d/1tROfDCP8meClFSDupPJViEQVIZ-Fsn36U9on7qSERzs/edit?usp=sharing&quot;) ## Sheet-identifying info appears to be a browser URL. ## googlesheets will attempt to extract sheet key from the URL. ## Putative key: 1tROfDCP8meClFSDupPJViEQVIZ-Fsn36U9on7qSERzs ## Auto-refreshing stale OAuth token. ## Sheet successfully identified: &quot;R 4 Progressive Campaigns&quot; # read the `weekly_canvas` tab weekly_canvass &lt;- gs_read(sheet, &quot;weekly_canvass&quot;) ## Accessing worksheet titled &#39;weekly_canvass&#39;. ## Warning: Missing column names filled in: &#39;X5&#39; [5], &#39;X6&#39; [6], &#39;X7&#39; [7] ## Parsed with column specification: ## cols( ## turf_code = col_character(), ## week = col_double(), ## n_pledged = col_double(), ## vol_yes = col_double(), ## X5 = col_logical(), ## X6 = col_logical(), ## X7 = col_double(), ## `#NAME?` = col_logical() ## ) # read the `goals` tab goals &lt;- gs_read(sheet, &quot;goals&quot;) ## Accessing worksheet titled &#39;goals&#39;. ## Parsed with column specification: ## cols( ## week = col_double(), ## region = col_character(), ## goal = col_double() ## ) weekly_canvass ## # A tibble: 66 x 8 ## turf_code week n_pledged vol_yes X5 X6 X7 `#NAME?` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 A 1 114 41 NA NA 130 NA ## 2 A 2 109 28 NA NA 130 NA ## 3 A 3 96 33 NA NA 130 NA ## 4 A 4 121 34 NA NA 130 NA ## 5 A 5 95 32 NA NA 130 NA ## 6 A 6 99 29 NA NA 130 NA ## 7 A 7 78 28 NA NA 130 NA ## 8 A 8 111 29 NA NA 130 NA ## 9 A 9 119 34 NA NA 130 NA ## 10 A 10 119 27 NA NA 130 NA ## # … with 56 more rows goals ## # A tibble: 312 x 3 ## week region goal ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 A 120 ## 2 1 B 130 ## 3 1 C 70 ## 4 1 D 120 ## 5 1 E 90 ## 6 1 F 130 ## 7 2 A 110 ## 8 2 B 90 ## 9 2 C 130 ## 10 2 D 70 ## # … with 302 more rows Notice that this code creates two tibbles in memory. Now everything else is the same. We will work within the context of an R Markdown document (intro to R Markdown). We want to create a simple report which will be emailed out to the organizing director each morning with the most up to date weekly PTG. Since this is a weekly report, we want to filter to the current week. In this case, the most recent data is from the 11th week of the month. We will filter both the weekly_canvass and goals tibbles to these weeks and then join. Note that it is important to filter before joining as joining can be computationally intensive. We want to reduce the data before joining it. current_week &lt;- weekly_canvass %&gt;% filter(week == 11) %&gt;% left_join(filter(goals, week == 11), by = c(&quot;turf_code&quot; = &quot;region&quot;, &quot;week&quot;)) %&gt;% mutate(ptg = n_pledged / goal) current_week ## # A tibble: 6 x 10 ## turf_code week n_pledged vol_yes X5 X6 X7 `#NAME?` goal ptg ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 11 76 20 NA NA 130 NA 90 0.844 ## 2 B 11 51 20 NA NA NA NA 50 1.02 ## 3 C 11 87 17 NA NA NA NA 130 0.669 ## 4 D 11 83 31 NA NA NA NA 60 1.38 ## 5 E 11 55 20 NA NA NA NA 70 0.786 ## 6 F 11 88 29 NA NA NA NA 70 1.26 While it nice to have each region’s PTG, it’s also useful to have the entire program weekly PTG. We can create an aggregate table and bind it to the existing table. totals &lt;- current_week %&gt;% bind_rows( current_week %&gt;% summarise(n_pledged = sum(n_pledged), goal = sum(goal), ptg = n_pledged / goal, vol_yes = sum(vol_yes), turf_code = &quot;Total&quot;, week = mean(week)) ) totals ## # A tibble: 7 x 10 ## turf_code week n_pledged vol_yes X5 X6 X7 `#NAME?` goal ptg ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 11 76 20 NA NA 130 NA 90 0.844 ## 2 B 11 51 20 NA NA NA NA 50 1.02 ## 3 C 11 87 17 NA NA NA NA 130 0.669 ## 4 D 11 83 31 NA NA NA NA 60 1.38 ## 5 E 11 55 20 NA NA NA NA 70 0.786 ## 6 F 11 88 29 NA NA NA NA 70 1.26 ## 7 Total 11 440 137 NA NA NA NA 470 0.936 totals %&gt;% ggplot(aes(turf_code, ptg)) + geom_col() + geom_hline(yintercept = 1, lty = 2, alpha = .4) + theme_minimal() + scale_y_continuous(labels = scales::percent_format()) + labs(title = &quot;Weekly PTG&quot;, y = &quot;% to goal&quot;, x = &quot;Turf Code&quot;) It is important that a clean table is presented alongside the chart. For this we will use knitr::kable(). totals %&gt;% mutate(ptg = ptg * 100) %&gt;% select(`Turf Code` = turf_code, `# Pledged` = n_pledged, Goal = goal, `% to Goal` = ptg) %&gt;% knitr::kable(digits = 2) Turf Code # Pledged Goal % to Goal A 76 90 84.44 B 51 50 102.00 C 87 130 66.92 D 83 60 138.33 E 55 70 78.57 F 88 70 125.71 Total 440 470 93.62 "],
["texting.html", "Chapter 4 texting", " Chapter 4 texting canvass &lt;- read_csv(&quot;data/canvassing_results.csv&quot;) ## Parsed with column specification: ## cols( ## van_id = col_double(), ## date = col_date(format = &quot;&quot;), ## vol_yes = col_double() ## ) van_names &lt;- read_csv(&quot;data/van_names.csv&quot;) ## Parsed with column specification: ## cols( ## van_id = col_double(), ## first_name = col_character(), ## last_name = col_character(), ## date_of_birth = col_date(format = &quot;&quot;), ## age = col_double() ## ) turf_lookup &lt;- read_csv(&quot;data/van_turf_lookup.csv&quot;) ## Parsed with column specification: ## cols( ## van_id = col_double(), ## turf_code = col_character() ## ) universe &lt;- inner_join(canvass, van_names) %&gt;% group_by(van_id) %&gt;% # for duplicates grab the one where they indicated vol yes top_n(1, wt = vol_yes) %&gt;% # make sure there is only 1 observation per person in the case that # duplicates had the same vol_yes result sample_n(size = 1) %&gt;% ungroup() %&gt;% #join region for hypothetical polling location / organizer info left_join(turf_lookup) ## Joining, by = &quot;van_id&quot; ## Joining, by = &quot;van_id&quot; We want the message to be coming from the proper regional organizing director (ROD). We will make some fake names for our RODs. We will create a named vector where the name is the turf code and the value is the organizer’s name (sampled from the babynames package / dataset cite here). organizers &lt;- c(&quot;Rosaleen&quot;, &quot;Larissa&quot;, &quot;Lafayette&quot;, &quot;Theo&quot;, &quot;Zamere&quot;, &quot;Colleen&quot;) names(organizers) &lt;- LETTERS[1:6] organizers ## A B C D E F ## &quot;Rosaleen&quot; &quot;Larissa&quot; &quot;Lafayette&quot; &quot;Theo&quot; &quot;Zamere&quot; &quot;Colleen&quot; We will use stringr::str_replace_all() to create an organizer column universe %&gt;% mutate(organizer = str_replace_all(turf_code, organizers)) %&gt;% select(organizer, everything()) ## # A tibble: 6,004 x 9 ## organizer van_id date vol_yes first_name last_name date_of_birth ## &lt;chr&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; ## 1 Larissa 1 2019-01-05 1 Timika Ehrsam 1970-01-03 ## 2 Zamere 2 2019-01-30 1 Johanna Gorden 1973-12-15 ## 3 Zamere 3 2019-02-27 0 Parys Stoelting 1997-02-15 ## 4 Larissa 4 2019-01-06 0 Lavell Dewall 1992-10-23 ## 5 Lafayette 5 2019-03-02 0 Brenisha Pachter 1977-07-05 ## 6 Zamere 6 2019-01-13 1 Hoang Millon 1992-02-29 ## 7 Larissa 7 2019-01-14 1 Rishith Pisciotto 1987-09-25 ## 8 Lafayette 8 2019-01-28 1 Maximilian Arakawa 1999-05-14 ## 9 Theo 9 2019-02-18 0 Timmie Schlag 1965-06-12 ## 10 Rosaleen 10 2019-02-05 0 Swetha Spreitzer 2000-12-08 ## # … with 5,994 more rows, and 2 more variables: age &lt;dbl&gt;, turf_code &lt;chr&gt; Say each region has their own unique polling location (realistically this will be a much more fine grain dataset that you can join on). We can specify the polling locations using a case_when() function call. We will build upon the previous pipe line. In case when you specify a logical statement and then return a value using the ~—i.e. something == TRUE ~ &quot;if true value&quot;. universe_locations &lt;- universe %&gt;% mutate(organizer = str_replace_all(turf_code, organizers), polling_place = case_when( turf_code == &quot;A&quot; ~ &quot;Community Center&quot;, turf_code == &quot;B&quot; ~ &quot;High School&quot;, turf_code == &quot;C&quot; ~ &quot;Town Hall&quot;, turf_code == &quot;D&quot; ~ &quot;Elementary School&quot;, turf_code == &quot;E&quot; ~ &quot;Rotary Club&quot;, turf_code == &quot;F&quot; ~ &quot;Senior Center&quot; ) ) universe_locations ## # A tibble: 6,004 x 10 ## van_id date vol_yes first_name last_name date_of_birth age ## &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 1 2019-01-05 1 Timika Ehrsam 1970-01-03 49 ## 2 2 2019-01-30 1 Johanna Gorden 1973-12-15 46 ## 3 3 2019-02-27 0 Parys Stoelting 1997-02-15 22 ## 4 4 2019-01-06 0 Lavell Dewall 1992-10-23 27 ## 5 5 2019-03-02 0 Brenisha Pachter 1977-07-05 42 ## 6 6 2019-01-13 1 Hoang Millon 1992-02-29 27 ## 7 7 2019-01-14 1 Rishith Pisciotto 1987-09-25 32 ## 8 8 2019-01-28 1 Maximilian Arakawa 1999-05-14 20 ## 9 9 2019-02-18 0 Timmie Schlag 1965-06-12 54 ## 10 10 2019-02-05 0 Swetha Spreitzer 2000-12-08 19 ## # … with 5,994 more rows, and 3 more variables: turf_code &lt;chr&gt;, ## # organizer &lt;chr&gt;, polling_place &lt;chr&gt; Generally, it is useful to segment texting scripts to allow for more tailored messaging. It is recommended to treat your potential volunteers differently than those who have not indicated a desire to volunteer. Let’s go ahead and create two different tibbles, one for vol yes and vol no. Based on this, we will create custom scripts. vol_yes &lt;- filter(universe_locations, vol_yes == 1) vol_no &lt;- filter(universe_locations, vol_yes == 0) At this point you should always check to see if your segmentation has missed anyone. The sum of the number of rows in your two tables should add up to the total number of rows in the original tibble (universe_locations). Let’s perform that sanity check before moving on. nrow(vol_yes) + nrow(vol_no) == nrow(universe_locations) ## [1] TRUE This returns TRUE, we are good to move onward! If there were any missing rows, I would recommend finding a way to incorporate them into some generic universe. The next step is to create the script. The package glue allows us to create character strings with the expressions or values from a tibble. Learn more here. vol_yes_message &lt;- vol_yes %&gt;% mutate(message = glue::glue(&quot;Hi {first_name} this is {organizer} with Abraham Lincoln for the Union! The election is right around the corner. We need all the help we can get, can we count on you to volunteer at {polling_place} on election day?&quot;)) vol_no_message &lt;- vol_no %&gt;% mutate(message = glue::glue(&quot;Hi {first_name} this is {organizer} with Abraham Lincoln for the Union! The election is right around the corner. Your polling location is at the {polling_place}. Can we count on your vote?&quot;)) messages &lt;- bind_rows(vol_yes_message, vol_no_message) ## Warning in bind_rows_(x, .id): Vectorizing &#39;glue&#39; elements may not preserve ## their attributes ## Warning in bind_rows_(x, .id): Vectorizing &#39;glue&#39; elements may not preserve ## their attributes select(messages, message) ## # A tibble: 6,004 x 1 ## message ## &lt;chr&gt; ## 1 Hi Timika this is Larissa with Abraham Lincoln for the Union! The elect… ## 2 Hi Johanna this is Zamere with Abraham Lincoln for the Union! The elect… ## 3 Hi Hoang this is Zamere with Abraham Lincoln for the Union! The electio… ## 4 Hi Rishith this is Larissa with Abraham Lincoln for the Union! The elec… ## 5 Hi Maximilian this is Lafayette with Abraham Lincoln for the Union! The… ## 6 Hi Deeksha this is Lafayette with Abraham Lincoln for the Union! The el… ## 7 Hi Therron this is Lafayette with Abraham Lincoln for the Union! The el… ## 8 Hi Lonney this is Lafayette with Abraham Lincoln for the Union! The ele… ## 9 Hi Robby this is Theo with Abraham Lincoln for the Union! The election … ## 10 Hi Siah this is Rosaleen with Abraham Lincoln for the Union! The electi… ## # … with 5,994 more rows Once you have created your custom messaging you can write this to a csv and upload it into a peer to peer texting platform like Relay and Hustle. In there you can, hopefully, map the VAN IDs so that the text messages are recorded in VAN (talk to your VAN Admin about setting up these integrations). One problem that you might face with platforms like Relay and Hustle is that custom fields can have a character limit. There are a few ways to handle this. One way is by recreating the custom messages within the platform themselves. However, I have found this historically somewhat cumbersom. My work around was to split each sentence into it’s own custom field. We can split the message into the sentences. This will create a list column which we will then unnest (working with list columns by Garret Grolemund). final_message &lt;- messages %&gt;% mutate(message = str_split(message, boundary(&quot;sentence&quot;))) %&gt;% unnest() %&gt;% group_by(van_id) %&gt;% mutate(message_number = row_number(), message_number = paste0(&quot;message_&quot;,message_number)) %&gt;% ungroup() %&gt;% spread(message_number, message) select(final_message, contains(&quot;message_&quot;)) ## # A tibble: 6,004 x 4 ## message_1 message_2 message_3 message_4 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 &quot;Hi Timika this is La… &quot;The election i… We need all the help … &lt;NA&gt; ## 2 &quot;Hi Johanna this is Z… &quot;The election i… We need all the help … &lt;NA&gt; ## 3 &quot;Hi Hoang this is Zam… &quot;The election i… We need all the help … &lt;NA&gt; ## 4 &quot;Hi Rishith this is L… &quot;The election i… We need all the help … &lt;NA&gt; ## 5 &quot;Hi Maximilian this i… &quot;The election i… We need all the help … &lt;NA&gt; ## 6 &quot;Hi Deeksha this is L… &quot;The election i… We need all the help … &lt;NA&gt; ## 7 &quot;Hi Therron this is L… &quot;The election i… We need all the help … &lt;NA&gt; ## 8 &quot;Hi Lonney this is La… &quot;The election i… We need all the help … &lt;NA&gt; ## 9 &quot;Hi Robby this is The… &quot;The election i… We need all the help … &lt;NA&gt; ## 10 &quot;Hi Siah this is Rosa… &quot;The election i… We need all the help … &lt;NA&gt; ## # … with 5,994 more rows Final step: upload to relay / hustle / whatever platform you use. Blast ’em. "],
["google-trends-results.html", "Chapter 5 google trends results 5.1 Google Trends Data 5.2 trendyy 5.3 Visualizing Trends", " Chapter 5 google trends results Over the past few years we have seen Google Trends becoming quite ubiquitous in politics. Pundits have used Google seach trends as talking points. It is not uncommon to hear news about a candidates search trends the days following a town hall or significant rally. It seems that Google trends are becoming the go to proxy for a candidate’s salience. As a campaign, you are interested in the popularity of a candidate relative to another one. If candidate A has seen a gain from 50 to 70, that is all well and good. But how does that compare with candidates C and D? There are others potential use cases—that may be less fraught with media interruptions. For example, one can keep track of the popularity of possible policy issues—i.e. healthcare, gun safety, women’s rights. Though the usefulness of Google Trends search popularity is still unclear, it may be something that your campaign might like to track. In this chapter we will explore how to acquire and utilize trend data using R. This chapter will describe how one can utilize Google Trends data to compare candidate search popularity and view related search terms. This will be done with the tidyverse, and the package trendyy for accessing this data. 5.1 Google Trends Data 5.1.1 Relative Popularity The key metric that Google Trends provides is the relative popularity of a search term by a given geography. Relative search popularity is scaled from 0 to 100. This number is scaled based on population and geography size (for more information go here). This number may be useful on it’s own, but the strength of Google Trends is it’s ability to compare multiple terms. Using Google Trends we can compare up to 5 search terms—presumably candidates. 5.1.2 Related Queries In addition to popularity, Google Trends provides you with related queries. This can help your media team understand in what context their candidate is being associated online. 5.2 trendyy Now that we have an intuition of how Google Trends may be utilized, we will look at how actually acquire these data in R. To get started install the package using install.packages(&quot;trendyy&quot;). Once the package is installed, load the tidyverse and trendyy. library(trendyy) library(tidyverse) In this example we will look at the top five polling candidates as of today (6/10/2019). These are, in no particular order, Joe Biden, Kamala Harris, Beto O’Rourke, Bernie Sanders, and Elizabeth Warren. Create a vector with the search terms that you will use (in this case the above candidates). candidates &lt;- c(&quot;Joe Biden&quot;, &quot;Kamala Harris&quot;, &quot;Beto O&#39;Rourke&quot;, &quot;Bernie Sanders&quot;, &quot;Elizabeth Warren&quot;) Next we will use the trendyy package to get search popularity. The function trendy() has three main arguments: search_terms, from, and to (in the form of &quot;yyyy-mm-dd&quot;). The first argument is the only mandatory one. Provide a vector of length 5 or less as the first argument. Here we will use the candidates vector and look at data from the past two weeks. I will create two variables for the beginning and end dates. This will be to demonstrate how functions can be used to programatically search date ranges. # to today end &lt;- Sys.Date() # from 2 weeks ago begin &lt;- Sys.Date() - 14 Pass these arguments to trendy() and save them to a variable. candidate_trends &lt;- trendy(search_terms = candidates, from = begin, to = end) candidate_trends ## ~Trendy results~ ## ## Search Terms: Joe Biden, Kamala Harris, Beto O&#39;Rourke, Bernie Sanders, Elizabeth Warren ## ## (&gt;^.^)&gt; ~~~~~~~~~~~~~~~~~~~~ summary ~~~~~~~~~~~~~~~~~~~~ &lt;(^.^&lt;) ## # A tibble: 5 x 5 ## keyword max_hits min_hits from to ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;date&gt; &lt;date&gt; ## 1 Bernie Sanders 100 58 2019-07-15 2019-07-25 ## 2 Beto O&#39;Rourke 2 1 2019-07-15 2019-07-25 ## 3 Elizabeth Warren 57 37 2019-07-15 2019-07-25 ## 4 Joe Biden 58 37 2019-07-15 2019-07-25 ## 5 Kamala Harris 80 53 2019-07-15 2019-07-25 Trendy creates an object of class trendy see class(candidate_trends) trendy. There are a number of accessor functions. We will use get_interest() and get_related_queries(). See the documentation of the others. To access to relative popularity, we will use get_interest(trendy). popularity &lt;- get_interest(candidate_trends) popularity ## # A tibble: 55 x 7 ## date hits geo time keyword gprop category ## &lt;dttm&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2019-07-15 00:00:00 50 world 2019-07-15 2… Joe Bid… web All catego… ## 2 2019-07-16 00:00:00 58 world 2019-07-15 2… Joe Bid… web All catego… ## 3 2019-07-17 00:00:00 49 world 2019-07-15 2… Joe Bid… web All catego… ## 4 2019-07-18 00:00:00 48 world 2019-07-15 2… Joe Bid… web All catego… ## 5 2019-07-19 00:00:00 45 world 2019-07-15 2… Joe Bid… web All catego… ## 6 2019-07-20 00:00:00 37 world 2019-07-15 2… Joe Bid… web All catego… ## 7 2019-07-21 00:00:00 49 world 2019-07-15 2… Joe Bid… web All catego… ## 8 2019-07-22 00:00:00 43 world 2019-07-15 2… Joe Bid… web All catego… ## 9 2019-07-23 00:00:00 37 world 2019-07-15 2… Joe Bid… web All catego… ## 10 2019-07-24 00:00:00 37 world 2019-07-15 2… Joe Bid… web All catego… ## # … with 45 more rows For related queries we will use get_related_queries(trendy). Note that you can either pipe the object or pass it directly. candidate_trends %&gt;% get_related_queries() %&gt;% # picking queries for a random candidate filter(keyword == sample(candidates, 1)) ## # A tibble: 0 x 5 ## # … with 5 variables: subject &lt;chr&gt;, related_queries &lt;chr&gt;, value &lt;chr&gt;, ## # keyword &lt;chr&gt;, category &lt;chr&gt; 5.3 Visualizing Trends I’m guessing your director enjoys charts—so do I. To make the data more accessible, use the popularity tibble to create a time series chart of popularity over the past two weeks. We will use ggplot2. Remember that time should be displayed on the x axis. We want to have a line for each candidate, so map the color aesthetic to the keyword. ggplot(popularity, aes(x = date, y = hits, color = keyword)) + geom_line() + labs(x = &quot;&quot;, y = &quot;Search Popularity&quot;, title = &quot;Google popularity of top 5 polling candidates&quot;) + theme_minimal() + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) "],
["web-scraping-polling-use-case.html", "Chapter 6 Web-Scraping: Polling use case 6.1 Understanding rvest 6.2 Example 6.3 Creating historic polling data", " Chapter 6 Web-Scraping: Polling use case A very important metric to keep track of is how your candidate is polling. Are they gaining a lead in the polls or falling behind? This data is often reported via traditional news organizations or some other mediums. The supposed demi-God and mythical pollster Nate Silver’s organization FiveThirtyEight does a wonderful job aggregating polls. Their page National 2020 Democratic Presidential Primary Polls has a table of the most recent polls from many different pollsters. In this use case we will acquire this data by web scraping using rvest. We will also go over ways to programatically save polls results to a text file. Saving polling results can allow you present a long term view of your candidate’s growth during the quarter. 6.1 Understanding rvest This use case will provide a cursory overview of the package rvest. To learn more go here. Web scraping is the process of extracting data from a website. Websites are written in HTML and CSS. There are a few aspects of these languages that are used in web scraping that is important to know. HTML is written in a series of what are call tags. A tag is a set of characters wrapped in angle brackets—i.e. &lt;img&gt;. With CSS (cascading style sheets), web developers can give unique identifiers to a tag. Classes can also be assigned to a tag. Think of these as group. With web scraping we can specify a particular part of a website by it’s HTML tag and perhaps it’s class or ID. rvest provides a large set of functions to make this simpler. 6.2 Example For this example we will be scraping FiveThirtyEight’s aggregated poll table. The table can be found at https://projects.fivethirtyeight.com/2020-primaries/democratic/national/. Before we begin, we must always prepare our workspace. Mise en place. library(rvest) ## Loading required package: xml2 ## ## Attaching package: &#39;rvest&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## pluck ## The following object is masked from &#39;package:readr&#39;: ## ## guess_encoding library(tidyverse) The first thing we will have to do is specify what page we will be scraping from. html_session() will simulate a session in an html browser. By providing a URL to html_session() we will then be able to access the underlying code of that page. Create an object called session by providing the FiveThirtyEight URL to html_session(). session &lt;- html_session(&quot;https://projects.fivethirtyeight.com/2020-primaries/democratic/national/&quot;) The next and most important step is to identify which piece of HTML code contains the table. The easiest way to do this is to open up the webpage in Chrome and open up the Inspect Elements view (on Mac - ⌘ + Shift + C). Now that this is open, click the select element button at the top left corner of the inspection pane. Now hover over the table. You will see that the HTML element is highlighted. We can see that it is a table tag. Additionally we see that there are two different classes polls-table and tracker. To specify a class we put a preceding . to the class name—i.e. .class-name. If there are multiple classes we just append the second class name to it—i.e. .first-class.second-class. Be aware that these selectors can be quite finicky and be a bit difficult to figure out. You might need to do some googling or playing around with the selector. To actually access the content of this HTML element, we must specify the element using the proper selector. html_node() will be used to do this. Provide the html session and the CSS selector to html_node() to extract the HTML element. session %&gt;% html_node(&quot;.polls-table.tracker&quot;) ## {xml_node} ## &lt;table class=&quot;polls-table tracker&quot;&gt; ## [1] &lt;thead class=&quot;hide-mobile&quot; id=&quot;table-header&quot;&gt;&lt;tr&gt;\\n&lt;th class=&quot;new&quot;&gt;&lt; ... ## [2] &lt;tbody&gt;\\n&lt;tr class=&quot;visible-row&quot; data-id=&quot;99767&quot;&gt;\\n&lt;!-- Shared--&gt;&lt;td ... Here we see that this returns on object of class xml_node. This object returns some HTML code but it is still not entirely workable. Since this is an HTML table we want to extract we can use the handy html_table(). Note that if this wasn’t a table but rather text, you can use html_text(). session %&gt;% html_node(&quot;.polls-table.tracker&quot;) %&gt;% html_table() Take note of the extremely informative error. It appears we might have to deal with mismatching columns. session %&gt;% html_node(&quot;.polls-table.tracker&quot;) %&gt;% html_table(fill = TRUE) ## Dates Pollster ## 1 • Jul 21-23, 2019455 LV Jul 21-23, 2019 ## 2 • Jul 21-23, 2019600 LV Jul 21-23, 2019 ## 3 • Jul 15-21, 201917,285 LV Jul 15-21, 2019 ## 4 • Jul 15-17, 2019910 RV Jul 15-17, 2019 ## 5 • Jul 14-16, 2019572 LV Jul 14-16, 2019 ## 6 • Jul 2-16, 20195,548 RV Jul 2-16, 2019 ## 7 • Jul 8-14, 201916,504 LV Jul 8-14, 2019 ## 8 • Jul 12-13, 2019446 RV Jul 12-13, 2019 ## 9 • Jul 7-9, 2019400 LV Jul 7-9, 2019 ## 10 • Jul 7-9, 2019592 LV Jul 7-9, 2019 ## 11 • Jul 6-8, 2019481 LV Jul 6-8, 2019 ## 12 • Jul 1-7, 201916,599 LV Jul 1-7, 2019 ## 13 • Jun 30-Jul 2, 2019631 LV Jun 30-Jul 2, 2019 ## 14 • Jun 28-Jul 2, 20191,173 RV Jun 28-Jul 2, 2019 ## 15 • Jun 28-Jul 2, 20191,367 A Jun 28-Jul 2, 2019 ## 16 • Jun 27-Jul 2, 20191,522 LV Jun 27-Jul 2, 2019 ## Sample Sample Biden Sanders Warren Harris ## 1 AFox News 455 LV 33% 15% 12% ## 2 BYouGov 600 LV 25% 13% 18% ## 3 B-Morning Consult 17,285 LV 33% 18% 14% ## 4 C+HarrisX 910 RV 26% 14% 9% ## 5 BYouGov 572 LV 23% 13% 15% ## 6 D-SurveyMonkey 5,548 RV 25% 16% 16% ## 7 B-Morning Consult 16,504 LV 32% 19% 14% ## 8 C+HarrisX 446 RV 29% 16% 9% ## 9 A-NBC News/Wall Street Journal 400 LV 26% 13% 19% ## 10 BYouGov 592 LV 22% 11% 17% ## 11 B+Emerson College 481 LV 30% 15% 15% ## 12 B-Morning Consult 16,599 LV 31% 19% 13% ## 13 BYouGov 631 LV 21% 10% 18% ## 14 B+Ipsos 1,173 RV 24% 17% 11% ## 15 B+Ipsos 1,367 A 22% 16% 9% ## 16 YouGov Blue/Data for Progress 1,522 LV 23% 15% 22% ## Buttigieg O&#39;Rourke Booker Klobuchar Castro Yang Gabbard Gillibrand ## 1 10% 5% 2% 2% 3% 1% 3% 0% ## 2 9% 6% 2% 2% 1% 3% 2% 2% ## 3 13% 5% 3% 2% 1% 1% 2% 1% ## 4 10% 4% 4% 2% 1% 1% 1% 0% ## 5 10% 7% 2% 3% 1% 1% 1% 1% ## 6 14% 8% 3% 3% 1% 2% 2% 1% ## 7 13% 5% 3% 2% 1% 1% 2% 1% ## 8 11% 1% 3% 1% 1% 1% 0% 1% ## 9 13% 7% 2% 1% 1% 1% 2% 0% ## 10 14% 5% 2% 1% 1% 2% 1% 2% ## 11 15% 5% 4% 2% 1% 0% 3% 2% ## 12 14% 6% 3% 2% 1% 1% 1% 1% ## 13 13% 9% 3% 2% 1% 2% 0% 1% ## 14 11% 4% 3% 1% 1% 1% 3% 0% ## 15 10% 3% 3% 1% 0% 1% 2% 0% ## 16 17% 7% 2% 2% 1% 1% 2% 1% ## Hickenlooper Delaney Ryan Inslee de Blasio Bennet Bullock Williamson ## 1 1% 2% 1% 0% 0% 1% 0% 0% ## 2 0% 0% 0% 0% 0% 1% 0% 1% ## 3 1% 0% 1% 1% 0% 1% 0% 1% ## 4 1% 1% 1% 1% 0% 0% 0% 0% ## 5 1% 0% 0% 0% 0% 2% 1% 1% ## 6 1% 0% 0% 1% 0% 1% 1% 0% ## 7 1% 1% 1% 1% 0% 0% 1% 1% ## 8 1% 0% 1% 1% 0% 1% 0% 1% ## 9 0% 1% 1% 0% 1% 0% 1% 0% ## 10 0% 1% 0% 0% 0% 1% 0% 1% ## 11 0% 0% 0% 0% 1% 0% 1% 1% ## 12 1% 1% 1% 1% 0% 1% 0% 1% ## 13 1% 0% 0% 0% 1% 1% 1% 1% ## 14 1% 0% 0% 1% 0% 0% 0% 1% ## 15 1% 0% 0% 1% 0% 0% 0% 1% ## 16 0% 1% 1% 0% 1% 0% 0% 0% ## Moulton Steyer Messam Sestak H. Clinton Bloomberg M. Obama Brown Gravel ## 1 0% 0% 1% 0% 0% ## 2 0% 0% 1% 0% 0% ## 3 1% 0% 1% ## 4 0% 1% 1% 0% 0% ## 5 0% 0% 1% 0% 0% ## 6 1% 0% 0% 0% ## 7 0% 0% ## 8 0% 1% 0% 1% 0% ## 9 1% 0% ## 10 0% 0% 0% 0% ## 11 0% 0% 0% 0% ## 12 1% 0% ## 13 0% 0% 0% 0% ## 14 0% 0% 0% 0% ## 15 0% 0% 0% 0% ## 16 0% 0% 0% 0% ## Swalwell Kerry Abrams Holder McAuliffe Winfrey Ojeda Trump Cuomo ## 1 ## 2 0% ## 3 ## 4 0% ## 5 0% ## 6 0% ## 7 ## 8 1% ## 9 ## 10 0% 0% ## 11 1% 1% ## 12 ## 13 0% 0% ## 14 0% 0% ## 15 0% 0% ## 16 0% 0% ## Avenatti Kennedy Patrick Zuckerberg Pelosi Garcetti Newsom Schultz ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 ## 7 ## 8 ## 9 ## 10 ## 11 ## 12 ## 13 ## 14 ## 15 ## 16 ## Kaine Johnson Kucinich Lee Scott Sinema Warner NA ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 ## 7 ## 8 ## 9 ## 10 ## 11 ## 12 ## 13 ## 14 ## 15 ## 16 ## NA ## 1 Biden33%Sanders15%Warren12%Harris10%Buttigieg5%Klobuchar3%Yang3%Booker2%Hickenlooper2%O&#39;Rourke2%Castro1%de Blasio1%Delaney1%Gillibrand1%Steyer1%Bennet0%Bullock0%Gabbard0%Inslee0%Messam0%Ryan0%Williamson0%Moulton0%Sestak0% ## 2 Biden25%Warren18%Sanders13%Harris9%Buttigieg6%Castro3%Booker2%Gabbard2%O&#39;Rourke2%Yang2%Bullock1%de Blasio1%Klobuchar1%Steyer1%Bennet0%Delaney0%Gillibrand0%Gravel0%Hickenlooper0%Inslee0%Messam0%Moulton0%Ryan0%Sestak0%Williamson0% ## 3 Biden33%Sanders18%Warren14%Harris13%Buttigieg5%O&#39;Rourke3%Booker2%Yang2%Klobuchar1%Bullock1%Castro1%de Blasio1%Delaney1%Gabbard1%Gillibrand1%Ryan1%Steyer1%Williamson1%Bennet0%Hickenlooper0%Inslee0%Moulton0% ## 4 Biden26%Sanders14%Harris10%Warren9%Buttigieg4%O&#39;Rourke4%Booker2%Castro1%Delaney1%Gillibrand1%Hickenlooper1%Klobuchar1%Yang1%Moulton1%Ryan1%Steyer1%Gabbard0%Inslee0%Williamson0%Gravel0%Messam0%Bennet0%Bullock0%de Blasio0%Sestak0% ## 5 Biden23%Warren15%Sanders13%Harris10%Buttigieg7%Booker3%de Blasio2%O&#39;Rourke2%Bennet1%Bullock1%Castro1%Gabbard1%Gillibrand1%Klobuchar1%Steyer1%Yang1%Delaney0%Gravel0%Hickenlooper0%Inslee0%Messam0%Moulton0%Ryan0%Sestak0%Williamson0% ## 6 Biden25%Sanders16%Warren16%Harris14%Buttigieg8%O&#39;Rourke3%Booker3%Castro2%Yang2%Klobuchar1%Ryan1%Gillibrand1%Williamson1%Gabbard1%de Blasio1%Bennet1%Hickenlooper0%Inslee0%Delaney0%Sestak0%Bullock0%Gravel0%Moulton0%Messam0% ## 7 Biden32%Sanders19%Warren14%Harris13%Buttigieg5%O&#39;Rourke3%Yang2%Booker2%Bennet1%Bullock1%Castro1%Delaney1%Gabbard1%Gillibrand1%Hickenlooper1%Klobuchar1%Ryan1%de Blasio0%Inslee0%Moulton0%Williamson0% ## 8 Biden29%Sanders16%Harris11%Warren9%O&#39;Rourke3%Buttigieg1%Booker1%Bullock1%Gabbard1%Moulton1%Gillibrand1%Klobuchar1%Ryan1%de Blasio1%Delaney1%Gravel1%Messam1%Castro1%Hickenlooper0%Steyer0%Williamson0%Sestak0%Bennet0%Yang0%Inslee0% ## 9 Biden26%Warren19%Harris13%Sanders13%Buttigieg7%Yang2%O&#39;Rourke2%Klobuchar1%Castro1%Booker1%Inslee1%Williamson1%Delaney1%Hickenlooper1%Bennet1%Bullock0%de Blasio0%Gabbard0%Gillibrand0%Moulton0%Ryan0% ## 10 Biden22%Warren17%Harris14%Sanders11%Buttigieg5%Castro2%Gabbard2%O&#39;Rourke2%Booker1%Bullock1%de Blasio1%Hickenlooper1%Klobuchar1%Yang1%Bennet0%Delaney0%Gillibrand0%Gravel0%Inslee0%Messam0%Moulton0%Ryan0%Sestak0%Swalwell0%Williamson0% ## 11 Biden30%Sanders15%Harris15%Warren15%Buttigieg5%O&#39;Rourke4%Yang3%Gabbard2%Booker2%Bennet1%Swalwell1%Klobuchar1%Gravel1%Bullock1%Inslee1%de Blasio0%Castro0%Delaney0%Ryan0%Sestak0%Gillibrand0%Williamson0%Moulton0%Messam0%Hickenlooper0% ## 12 Biden31%Sanders19%Harris14%Warren13%Buttigieg6%O&#39;Rourke3%Booker2%Bullock1%Castro1%de Blasio1%Delaney1%Gabbard1%Gillibrand1%Hickenlooper1%Klobuchar1%Ryan1%Yang1%Williamson1%Bennet0%Inslee0%Moulton0% ## 13 Biden21%Warren18%Harris13%Sanders10%Buttigieg9%O&#39;Rourke3%Booker2%Castro2%Bennet1%Bullock1%de Blasio1%Gabbard1%Gillibrand1%Inslee1%Klobuchar1%Delaney0%Gravel0%Hickenlooper0%Messam0%Moulton0%Ryan0%Sestak0%Swalwell0%Williamson0%Yang0% ## 14 Biden24%Sanders17%Harris11%Warren11%Buttigieg4%O&#39;Rourke3%Yang3%Booker1%Castro1%Klobuchar1%Gillibrand1%Bullock1%Ryan1%Gabbard0%Hickenlooper0%Inslee0%Delaney0%Williamson0%Messam0%Swalwell0%Moulton0%Bennet0%de Blasio0%Gravel0%Sestak0% ## 15 Biden22%Sanders16%Harris10%Warren9%O&#39;Rourke3%Buttigieg3%Yang2%Booker1%Castro1%Gillibrand1%Bullock1%Ryan1%Klobuchar0%Gabbard0%Hickenlooper0%de Blasio0%Inslee0%Delaney0%Williamson0%Messam0%Swalwell0%Moulton0%Bennet0%Gravel0%Sestak0% ## 16 Biden23%Warren22%Harris17%Sanders15%Buttigieg7%O&#39;Rourke2%Yang2%Booker2%Klobuchar1%Inslee1%Hickenlooper1%Castro1%Delaney1%Gabbard1%Gillibrand0%Bennet0%de Blasio0%Swalwell0%Ryan0%Bullock0%Moulton0%Sestak0%Gravel0%Messam0%Williamson0% ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 159 rows ] This is much better! But based on visual inspection the column headers are not properly matched. There are a few things that need to be sorted out: there are two date columns, there are commas and percents where numeric columns should be, the column headers are a little messy, and the table isn’t a tibble (this is just personal preference). We will handle the final two issues first as they are easiest to deal with. The function clean_names() from janitor will handle the column headers, and as_tibble() will coerce the data.frame into a proper tibble. Save this semi-clean tibble into an object called polls. polls &lt;- session %&gt;% html_node(&quot;.polls-table.tracker&quot;) %&gt;% html_table(fill = TRUE) %&gt;% janitor::clean_names() %&gt;% as_tibble() polls ## # A tibble: 175 x 60 ## x dates pollster sample sample_2 biden sanders warren harris ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 • Jul … Jul 21-… AFox … 455 LV 33% 15% 12% ## 2 • Jul … Jul 21-… BYouG… 600 LV 25% 13% 18% ## 3 • Jul … Jul 15-… B-Mor… 17,285 LV 33% 18% 14% ## 4 • Jul … Jul 15-… C+Har… 910 RV 26% 14% 9% ## 5 • Jul … Jul 14-… BYouG… 572 LV 23% 13% 15% ## 6 • Jul … Jul 2-1… D-Sur… 5,548 RV 25% 16% 16% ## 7 • Jul … Jul 8-1… B-Mor… 16,504 LV 32% 19% 14% ## 8 • Jul … Jul 12-… C+Har… 446 RV 29% 16% 9% ## 9 • Jul … Jul 7-9… A-NBC… 400 LV 26% 13% 19% ## 10 • Jul … Jul 7-9… BYouG… 592 LV 22% 11% 17% ## # … with 165 more rows, and 51 more variables: buttigieg &lt;chr&gt;, ## # o_rourke &lt;chr&gt;, booker &lt;chr&gt;, klobuchar &lt;chr&gt;, castro &lt;chr&gt;, ## # yang &lt;chr&gt;, gabbard &lt;chr&gt;, gillibrand &lt;chr&gt;, hickenlooper &lt;chr&gt;, ## # delaney &lt;chr&gt;, ryan &lt;chr&gt;, inslee &lt;chr&gt;, de_blasio &lt;chr&gt;, ## # bennet &lt;chr&gt;, bullock &lt;chr&gt;, williamson &lt;chr&gt;, moulton &lt;chr&gt;, ## # steyer &lt;chr&gt;, messam &lt;chr&gt;, sestak &lt;chr&gt;, h_clinton &lt;chr&gt;, ## # bloomberg &lt;chr&gt;, m_obama &lt;chr&gt;, brown &lt;chr&gt;, gravel &lt;chr&gt;, ## # swalwell &lt;chr&gt;, kerry &lt;chr&gt;, abrams &lt;chr&gt;, holder &lt;chr&gt;, ## # mc_auliffe &lt;chr&gt;, winfrey &lt;chr&gt;, ojeda &lt;chr&gt;, trump &lt;chr&gt;, ## # cuomo &lt;chr&gt;, avenatti &lt;chr&gt;, kennedy &lt;chr&gt;, patrick &lt;chr&gt;, ## # zuckerberg &lt;chr&gt;, pelosi &lt;chr&gt;, garcetti &lt;chr&gt;, newsom &lt;chr&gt;, ## # schultz &lt;chr&gt;, kaine &lt;chr&gt;, johnson &lt;chr&gt;, kucinich &lt;chr&gt;, lee &lt;chr&gt;, ## # scott &lt;chr&gt;, sinema &lt;chr&gt;, warner &lt;chr&gt;, na &lt;chr&gt;, na_2 &lt;chr&gt; We want to shift over the column names to the right just once. Unfortunately there is no elegant way to do this (that I am aware of). We can see that the first column is completely useless so that can be removed. Once that column is removed we can reset the names this way they will be well aligned. We will start by creating a vector of the original column names. col_names &lt;- names(polls) col_names ## [1] &quot;x&quot; &quot;dates&quot; &quot;pollster&quot; &quot;sample&quot; ## [5] &quot;sample_2&quot; &quot;biden&quot; &quot;sanders&quot; &quot;warren&quot; ## [9] &quot;harris&quot; &quot;buttigieg&quot; &quot;o_rourke&quot; &quot;booker&quot; ## [13] &quot;klobuchar&quot; &quot;castro&quot; &quot;yang&quot; &quot;gabbard&quot; ## [17] &quot;gillibrand&quot; &quot;hickenlooper&quot; &quot;delaney&quot; &quot;ryan&quot; ## [21] &quot;inslee&quot; &quot;de_blasio&quot; &quot;bennet&quot; &quot;bullock&quot; ## [25] &quot;williamson&quot; &quot;moulton&quot; &quot;steyer&quot; &quot;messam&quot; ## [29] &quot;sestak&quot; &quot;h_clinton&quot; &quot;bloomberg&quot; &quot;m_obama&quot; ## [33] &quot;brown&quot; &quot;gravel&quot; &quot;swalwell&quot; &quot;kerry&quot; ## [37] &quot;abrams&quot; &quot;holder&quot; &quot;mc_auliffe&quot; &quot;winfrey&quot; ## [41] &quot;ojeda&quot; &quot;trump&quot; &quot;cuomo&quot; &quot;avenatti&quot; ## [45] &quot;kennedy&quot; &quot;patrick&quot; &quot;zuckerberg&quot; &quot;pelosi&quot; ## [49] &quot;garcetti&quot; &quot;newsom&quot; &quot;schultz&quot; &quot;kaine&quot; ## [53] &quot;johnson&quot; &quot;kucinich&quot; &quot;lee&quot; &quot;scott&quot; ## [57] &quot;sinema&quot; &quot;warner&quot; &quot;na&quot; &quot;na_2&quot; Unfortunately this also presents another issue. Once a column is deselected, there will be one more column name than column. So we will need to select all but the last element of the original names. We will create a vector called new_names. # identify the integer number of the last column last_col &lt;- length(col_names) - 1 # create a vector which will be used for the new names new_names &lt;- col_names[1:last_col] Now we can try implementing the hacky solution. Here we will deselect the first column and reset the names using setNames(). Following, we will use the mutate_at() variant to remove the percent sign from every candidate column and coerce them into integer columns. Here we will specify which variables to not mutate at within vars(). polls %&gt;% select(-1) %&gt;% setNames(new_names)%&gt;% select(-1) %&gt;% mutate_at(vars(-c(&quot;dates&quot;, &quot;pollster&quot;, &quot;sample&quot;, &quot;sample_2&quot;)), ~as.integer(str_remove(., &quot;%&quot;))) ## Warning in ~as.integer(str_remove(., &quot;%&quot;)): NAs introduced by coercion ## # A tibble: 175 x 58 ## dates pollster sample sample_2 biden sanders warren harris buttigieg ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Jul … AFox Ne… 455 LV 33 15 12 10 5 ## 2 Jul … BYouGov 600 LV 25 13 18 9 6 ## 3 Jul … B-Morni… 17,285 LV 33 18 14 13 5 ## 4 Jul … C+Harri… 910 RV 26 14 9 10 4 ## 5 Jul … BYouGov 572 LV 23 13 15 10 7 ## 6 Jul … D-Surve… 5,548 RV 25 16 16 14 8 ## 7 Jul … B-Morni… 16,504 LV 32 19 14 13 5 ## 8 Jul … C+Harri… 446 RV 29 16 9 11 1 ## 9 Jul … A-NBC N… 400 LV 26 13 19 13 7 ## 10 Jul … BYouGov 592 LV 22 11 17 14 5 ## # … with 165 more rows, and 49 more variables: o_rourke &lt;int&gt;, ## # booker &lt;int&gt;, klobuchar &lt;int&gt;, castro &lt;int&gt;, yang &lt;int&gt;, ## # gabbard &lt;int&gt;, gillibrand &lt;int&gt;, hickenlooper &lt;int&gt;, delaney &lt;int&gt;, ## # ryan &lt;int&gt;, inslee &lt;int&gt;, de_blasio &lt;int&gt;, bennet &lt;int&gt;, ## # bullock &lt;int&gt;, williamson &lt;int&gt;, moulton &lt;int&gt;, steyer &lt;int&gt;, ## # messam &lt;int&gt;, sestak &lt;int&gt;, h_clinton &lt;int&gt;, bloomberg &lt;int&gt;, ## # m_obama &lt;int&gt;, brown &lt;int&gt;, gravel &lt;int&gt;, swalwell &lt;int&gt;, kerry &lt;int&gt;, ## # abrams &lt;int&gt;, holder &lt;int&gt;, mc_auliffe &lt;int&gt;, winfrey &lt;int&gt;, ## # ojeda &lt;int&gt;, trump &lt;int&gt;, cuomo &lt;int&gt;, avenatti &lt;int&gt;, kennedy &lt;int&gt;, ## # patrick &lt;int&gt;, zuckerberg &lt;int&gt;, pelosi &lt;int&gt;, garcetti &lt;int&gt;, ## # newsom &lt;int&gt;, schultz &lt;int&gt;, kaine &lt;int&gt;, johnson &lt;int&gt;, ## # kucinich &lt;int&gt;, lee &lt;int&gt;, scott &lt;int&gt;, sinema &lt;int&gt;, warner &lt;int&gt;, ## # na &lt;int&gt; Now we must tidy the data. We will use tidyr::gather() to transform the data from wide to long. In short, gather takes the column headers (the key argument) and creates a new variable from the values of the columns (the value argument). In this case, we will create a new column called candidate from the column headers and a second column called points which are a candidates polling percentage. Next we deselect any columns that we do not want to be gathered. polls %&gt;% select(-1) %&gt;% setNames(new_names)%&gt;% select(-1) %&gt;% mutate_at(vars(-c(&quot;dates&quot;, &quot;pollster&quot;, &quot;sample&quot;, &quot;sample_2&quot;)), ~as.integer(str_remove(., &quot;%&quot;))) %&gt;% gather(candidate, points, -dates, -pollster, -sample, -sample_2) ## Warning in ~as.integer(str_remove(., &quot;%&quot;)): NAs introduced by coercion ## # A tibble: 9,450 x 6 ## dates pollster sample sample_2 candidate points ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Jul 21-23, 2… AFox News 455 LV biden 33 ## 2 Jul 21-23, 2… BYouGov 600 LV biden 25 ## 3 Jul 15-21, 2… B-Morning Consult 17,285 LV biden 33 ## 4 Jul 15-17, 2… C+HarrisX 910 RV biden 26 ## 5 Jul 14-16, 2… BYouGov 572 LV biden 23 ## 6 Jul 2-16, 20… D-SurveyMonkey 5,548 RV biden 25 ## 7 Jul 8-14, 20… B-Morning Consult 16,504 LV biden 32 ## 8 Jul 12-13, 2… C+HarrisX 446 RV biden 29 ## 9 Jul 7-9, 2019 A-NBC News/Wall Street J… 400 LV biden 26 ## 10 Jul 7-9, 2019 BYouGov 592 LV biden 22 ## # … with 9,440 more rows There are a few more house-keeping things that need to be done to improve this data set. sample_2 is rather uninformative. On the FiveThirtyEight website there is a key which describes what these values represent (A = ADULTS, RV = REGISTERED VOTERS, V = VOTERS, LV = LIKELY VOTERS). This should be specified in our data set. In addition the sample column ought to be cast into an integer column. And finally, those messy dates will need to be cleaned. My approach to this requires creating a function to handle this cleaning. First, the simple stuff. To do the first two above steps, we will continue our function chain and save it to a new variable polls_tidy. polls_tidy &lt;- polls %&gt;% select(-1) %&gt;% setNames(new_names)%&gt;% select(-1) %&gt;% mutate_at(vars(-c(&quot;dates&quot;, &quot;pollster&quot;, &quot;sample&quot;, &quot;sample_2&quot;)), ~as.integer(str_remove(., &quot;%&quot;))) %&gt;% gather(candidate, points, -dates, -pollster, -sample, -sample_2) %&gt;% mutate(sample_2 = case_when( sample_2 == &quot;RV&quot; ~ &quot;Registered Voters&quot;, sample_2 == &quot;LV&quot; ~ &quot;Likely Voters&quot;, sample_2 == &quot;A&quot; ~ &quot;Adults&quot;, sample_2 == &quot;V&quot; ~ &quot;Voters&quot; ), sample = as.integer(str_remove(sample, &quot;,&quot;))) ## Warning in ~as.integer(str_remove(., &quot;%&quot;)): NAs introduced by coercion polls_tidy ## # A tibble: 9,450 x 6 ## dates pollster sample sample_2 candidate points ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Jul 21-23, … AFox News 455 Likely Voters biden 33 ## 2 Jul 21-23, … BYouGov 600 Likely Voters biden 25 ## 3 Jul 15-21, … B-Morning Consult 17285 Likely Voters biden 33 ## 4 Jul 15-17, … C+HarrisX 910 Registered V… biden 26 ## 5 Jul 14-16, … BYouGov 572 Likely Voters biden 23 ## 6 Jul 2-16, 2… D-SurveyMonkey 5548 Registered V… biden 25 ## 7 Jul 8-14, 2… B-Morning Consult 16504 Likely Voters biden 32 ## 8 Jul 12-13, … C+HarrisX 446 Registered V… biden 29 ## 9 Jul 7-9, 20… A-NBC News/Wall Stre… 400 Likely Voters biden 26 ## 10 Jul 7-9, 20… BYouGov 592 Likely Voters biden 22 ## # … with 9,440 more rows 6.2.1 Date cleaning Next we must work to clean the date field. I find that when working with a messy column, creating a single function which handles the cleaning is one of the most effective approaches. Here we will create a function which takes a value provided from the dates field and return a cleaned date. There are two unique cases I identified. There are poll dates which occurred during a single month, or a poll that spanned two months. The dates are separated by a single hyphen -. If we split the date at - we will either receive two elements with a month indicated or one month with a day and a day number. In the latter case we will have to carry over the month. Then the year can be appended to it and parsed as a date using the lubridate package. For more on lubridate visit here. The function will only return one date at a time. The two arguments will be date and .return to indicate whether the first or second date should be provided. The internals of this function rely heavily on the stringr package (see R for Data Science Chapter 14). switch() at the end of the function determines which date should be returned (see Advanced R Chapter 5). clean_date &lt;- function(date, .return = &quot;first&quot;) { # take date and split at the comma to get the year and the month-day combo date_split &lt;- str_split(date, &quot;,&quot;) %&gt;% # remove from list / coerce to vector unlist() %&gt;% # remove extra white space str_trim() # extract the year date_year &lt;- date_split[2] # split the month day portion and coerce to vector dates &lt;- unlist(str_split(date_split[1], &quot;-&quot;)) # paste the month day and year together then parse as date using `mdy()` first_date &lt;- paste(dates[1], date_year) %&gt;% lubridate::mdy() second_date &lt;- ifelse(!str_detect(dates[2], &quot;[A-z]+&quot;), yes = paste(str_extract(dates[1], &quot;[A-z]+&quot;), dates[2], date_year), no = paste(dates[2], date_year)) %&gt;% lubridate::mdy() switch(.return, first = return(first_date), second = return(second_date) ) } # test on a date clean_date(polls_tidy$dates[10], .return = &quot;first&quot;) ## [1] &quot;2019-07-07&quot; clean_date(polls_tidy$dates[10], .return = &quot;second&quot;) ## [1] &quot;2019-07-09&quot; We can use this new function to create two new columns poll_start and poll_end using mutate(). Following this we can deselect the original dates column, remove any observations missing a points value, remove duplicates using distinct(), and save this to polls_clean. polls_clean &lt;- polls_tidy %&gt;% mutate(poll_start = clean_date(dates, &quot;first&quot;), poll_end = clean_date(dates, &quot;second&quot;)) %&gt;% select(-dates) %&gt;% filter(!is.na(points)) %&gt;% distinct() polls_clean ## # A tibble: 3,136 x 7 ## pollster sample sample_2 candidate points poll_start poll_end ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;date&gt; &lt;date&gt; ## 1 AFox News 455 Likely Vo… biden 33 2019-07-21 2019-07-23 ## 2 BYouGov 600 Likely Vo… biden 25 2019-07-21 2019-07-23 ## 3 B-Morning Cons… 17285 Likely Vo… biden 33 2019-07-21 2019-07-23 ## 4 C+HarrisX 910 Registere… biden 26 2019-07-21 2019-07-23 ## 5 BYouGov 572 Likely Vo… biden 23 2019-07-21 2019-07-23 ## 6 D-SurveyMonkey 5548 Registere… biden 25 2019-07-21 2019-07-23 ## 7 B-Morning Cons… 16504 Likely Vo… biden 32 2019-07-21 2019-07-23 ## 8 C+HarrisX 446 Registere… biden 29 2019-07-21 2019-07-23 ## 9 A-NBC News/Wal… 400 Likely Vo… biden 26 2019-07-21 2019-07-23 ## 10 BYouGov 592 Likely Vo… biden 22 2019-07-21 2019-07-23 ## # … with 3,126 more rows 6.2.2 Visualization The cleaned data can be aggregated and visualized. avg_polls &lt;- polls_clean %&gt;% group_by(candidate) %&gt;% summarise(avg_points = mean(points, na.rm = TRUE), min_points = min(points, na.rm = TRUE), max_points = max(points, na.rm = TRUE), n_polls = n() - sum(is.na(points))) %&gt;% # identify how many polls candidate is in # remove candidates who appear in 50 or fewer polls: i.e. HRC filter(n_polls &gt; 50) %&gt;% arrange(-avg_points) avg_polls ## # A tibble: 24 x 5 ## candidate avg_points min_points max_points n_polls ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 biden 31.5 9 66 163 ## 2 sanders 18.7 4 42 164 ## 3 warren 10.3 2 43 164 ## 4 harris 9.68 2 41 164 ## 5 o_rourke 5.32 1 21 156 ## 6 buttigieg 5.27 0 21 131 ## 7 booker 2.90 0 9 155 ## 8 klobuchar 1.52 0 5 144 ## 9 yang 1.21 0 3 111 ## 10 castro 1.15 0 12 147 ## # … with 14 more rows avg_polls %&gt;% mutate(candidate = fct_reorder(candidate, avg_points)) %&gt;% ggplot(aes(candidate, avg_points)) + geom_col() + theme_minimal() + coord_flip() + labs(title = &quot;Polls Standings&quot;, x = &quot;&quot;, y = &quot;%&quot;) 6.3 Creating historic polling data It may become useful to have a running history of how candidates have been polling. We can use R to write a csv file of the data from FiveThirtyEight. However, what happens when the polls update? How we can we keep the previous data and the new data? We will work through an example using a combination of bind_rows() and distinct(). I want to emphasize that this is not a good practice if you need to scale to hundreds of thousand of rows. This works in this case as the data are inherently small. To start, I have created a sample dataset which contains 80% of these polls (maybe less by the time you do this!). Note that is probably best to version control this or have multiple copies as a failsafe. The approach we will take is to read in the historic polls data set and bind rows with the polls_clean data we have scraped. Next we remove duplicate rows using distinct(). old_polls &lt;- read_csv(&quot;data/polls.csv&quot;) ## Parsed with column specification: ## cols( ## pollster = col_character(), ## sample = col_double(), ## sample_2 = col_character(), ## candidate = col_character(), ## points = col_double(), ## poll_start = col_date(format = &quot;&quot;), ## poll_end = col_date(format = &quot;&quot;) ## ) old_polls ## # A tibble: 1,564 x 7 ## pollster sample sample_2 candidate points poll_start poll_end ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;date&gt; &lt;date&gt; ## 1 C+HarrisX 370 Registered… klobuchar 2 2019-06-06 2019-06-10 ## 2 C+HarrisX 448 Registered… gillibra… 1 2019-06-06 2019-06-10 ## 3 B-Morning Con… 11627 Likely Vot… harris 13 2019-06-06 2019-06-10 ## 4 B-Morning Con… 699 Registered… delaney 0 2019-06-06 2019-06-10 ## 5 C+HarrisX 743 Registered… williams… 1 2019-06-06 2019-06-10 ## 6 A-Quinnipiac … 559 Registered… gabbard 0 2019-06-06 2019-06-10 ## 7 B-Morning Con… 14250 Likely Vot… gillibra… 2 2019-06-06 2019-06-10 ## 8 A-Quinnipiac … 559 Registered… gillibra… 0 2019-06-06 2019-06-10 ## 9 B-Morning Con… 14250 Likely Vot… harris 6 2019-06-06 2019-06-10 ## 10 A+Monmouth Un… 330 Registered… warren 8 2019-06-06 2019-06-10 ## # … with 1,554 more rows updated_polls &lt;- bind_rows(old_polls, polls_clean) %&gt;% distinct() updated_polls ## # A tibble: 4,700 x 7 ## pollster sample sample_2 candidate points poll_start poll_end ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;date&gt; &lt;date&gt; ## 1 C+HarrisX 370 Registered… klobuchar 2 2019-06-06 2019-06-10 ## 2 C+HarrisX 448 Registered… gillibra… 1 2019-06-06 2019-06-10 ## 3 B-Morning Con… 11627 Likely Vot… harris 13 2019-06-06 2019-06-10 ## 4 B-Morning Con… 699 Registered… delaney 0 2019-06-06 2019-06-10 ## 5 C+HarrisX 743 Registered… williams… 1 2019-06-06 2019-06-10 ## 6 A-Quinnipiac … 559 Registered… gabbard 0 2019-06-06 2019-06-10 ## 7 B-Morning Con… 14250 Likely Vot… gillibra… 2 2019-06-06 2019-06-10 ## 8 A-Quinnipiac … 559 Registered… gillibra… 0 2019-06-06 2019-06-10 ## 9 B-Morning Con… 14250 Likely Vot… harris 6 2019-06-06 2019-06-10 ## 10 A+Monmouth Un… 330 Registered… warren 8 2019-06-06 2019-06-10 ## # … with 4,690 more rows Now you have a cleaned data set which has been integrated with the recently scraped data. Write this to a csv using write_csv() for later use. "],
["state-voter-files.html", "Chapter 7 State Voter Files 7.1 Motivation 7.2 Overview 7.3 Exercise", " Chapter 7 State Voter Files 7.1 Motivation Who one votes for is private, but when someone votes is a matter of public record. A state’s Secretary of State (SOS) maintains a public record of who voted. The accompanying data may vary state by state. For example, the state of New Hampshire does not record the age of the person voting. Companies such as Catalist have built their business around aggregating, cleaning, and enhancing public voter files. However, these databases can be quite expensive and are not updated at the same pace as the state voter file. 7.2 Overview In this section we will demonstrate how to programatically download and clean the state voterfile. From there, we will identify potential voters and canvassing targets. Once those targets have been identified, they can be uploaded as a list into VAN based on their SOS ID which should be present depending on your provider. The OH SOS website provide links to the voter file which are updated frequently. These files were last updated on July 19th, 2019 as of today (July 21st, 2019). We will combine the webscraping tools (rvest) that we previously learned and combine them with dplyr and data.table—a package that works exceptionally well with large data, see the wiki for a primer. 7.3 Exercise As always, let’s set up our workspace. library(rvest) library(data.table) library(dplyr) The first step is to use rvest to identify the URLs that we can use to download the voter-file. To do this, use the inspector tool in your web browser and identify the HTML elements of interest. In this use case, we will specify the highlight-row class and the a (anchor) tag. The a tag is used to create hyperlinks within a document. The href attribute is used to specify the hyperlink. We can extract the href attribute using rvest::html_attr(). 7.3.1 Identifying download links session &lt;- html_session(&quot;https://www6.sos.state.oh.us/ords/f?p=VOTERFTP:STWD:::#stwdVtrFiles&quot;) html_nodes(session, &quot;.highlight-row a&quot;) %&gt;% html_attr(&quot;href&quot;) ## [1] &quot;f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:363&quot; ## [2] &quot;f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:364&quot; ## [3] &quot;f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:365&quot; ## [4] &quot;f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:366&quot; Notice that this does not actually provide the full URL that is needed, but rather the query parameters. We can iteratively append this to the base url—in this case https://www6.sos.state.oh.us/ords/—using purrr::map(). file_urls &lt;- html_nodes(session, &quot;.highlight-row a&quot;) %&gt;% html_attr(&quot;href&quot;) %&gt;% purrr::map_chr(~paste0(&quot;https://www6.sos.state.oh.us/ords/&quot;, .)) file_urls ## [1] &quot;https://www6.sos.state.oh.us/ords/f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:363&quot; ## [2] &quot;https://www6.sos.state.oh.us/ords/f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:364&quot; ## [3] &quot;https://www6.sos.state.oh.us/ords/f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:365&quot; ## [4] &quot;https://www6.sos.state.oh.us/ords/f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:366&quot; With that, we now have the file paths for the four statewide voter file data sets. For the sake of computation and memory, we will only work with the first URL. 7.3.2 Download the voter file Now that we have the links to the voter file, we can use R to download them using download.file(). The first argument is the link to the file, the second is the destination of that file. Here we are saving the first file into the data folder. You can also do this iteratively using purrr::map(). # download the file as a .txt.gz (that&#39;s the file format if you download it from the web) download.file(file_urls[1], destfile = &quot;data/SWVF_1_22 (Adams-Erie).txt.gz&quot;) Note that the file is in .gz compressed format. We can uncompress this using R.utils::gunzip() which will return the compressed file. R.utils::gunzip(&quot;data/SWVF_1_22 (Adams-Erie).txt.gz&quot;) data.table reads text files using fread(). Since this file is very large, we will take only the first 10,000 observations. Do this by setting the nrows argument to 10000. Since data.table is an extension upon the data.frame, we can combine both data.table aand dplyr functions. 7.3.3 Voter file exploratoration swvf &lt;- fread(&quot;data/SWVF_1_22 (Adams-Erie).txt&quot;, nrows = 10000) Do your due dilligence and look at all 106 columns. This is a great time to embrace dirty data. Are the data tidy? glimpse(swvf) ## Observations: 10,000 ## Variables: 106 ## $ SOS_VOTERID &lt;chr&gt; &quot;OH0016238254&quot;, &quot;OH0019414074&quot;, &quot;O… ## $ COUNTY_NUMBER &lt;int&gt; 6, 2, 6, 9, 18, 13, 18, 18, 13, 4,… ## $ COUNTY_ID &lt;int&gt; 21511, 1010005, 40055, 482703, 204… ## $ LAST_NAME &lt;chr&gt; &quot;KUETHER&quot;, &quot;GEMLICK&quot;, &quot;KITCHEN&quot;, &quot;… ## $ FIRST_NAME &lt;chr&gt; &quot;BARBARA&quot;, &quot;JODI&quot;, &quot;LESLIE&quot;, &quot;AMAN… ## $ MIDDLE_NAME &lt;chr&gt; &quot;A&quot;, &quot;LYN&quot;, &quot;L&quot;, &quot;LEIGH&quot;, &quot;J&quot;, &quot;L&quot;… ## $ SUFFIX &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ DATE_OF_BIRTH &lt;chr&gt; &quot;1969-11-15&quot;, &quot;1972-08-19&quot;, &quot;1969-… ## $ REGISTRATION_DATE &lt;chr&gt; &quot;1998-02-23&quot;, &quot;2007-01-29&quot;, &quot;2008-… ## $ VOTER_STATUS &lt;chr&gt; &quot;ACTIVE&quot;, &quot;ACTIVE&quot;, &quot;ACTIVE&quot;, &quot;ACT… ## $ PARTY_AFFILIATION &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;D&quot;, &quot;… ## $ RESIDENTIAL_ADDRESS1 &lt;chr&gt; &quot;725 OAKWOOD DR&quot;, &quot;3464 WOODHAVEN … ## $ RESIDENTIAL_SECONDARY_ADDR &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ RESIDENTIAL_CITY &lt;chr&gt; &quot;MINSTER&quot;, &quot;LIMA&quot;, &quot;ST MARYS&quot;, &quot;MO… ## $ RESIDENTIAL_STATE &lt;chr&gt; &quot;OH&quot;, &quot;OH&quot;, &quot;OH&quot;, &quot;OH&quot;, &quot;OH&quot;, &quot;OH&quot;… ## $ RESIDENTIAL_ZIP &lt;int&gt; 45865, 45806, 45885, 45050, 44105,… ## $ RESIDENTIAL_ZIP_PLUS4 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ RESIDENTIAL_COUNTRY &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ RESIDENTIAL_POSTALCODE &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ MAILING_ADDRESS1 &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ MAILING_SECONDARY_ADDRESS &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ MAILING_CITY &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ MAILING_STATE &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ MAILING_ZIP &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ MAILING_ZIP_PLUS4 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ MAILING_COUNTRY &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ MAILING_POSTAL_CODE &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ CAREER_CENTER &lt;chr&gt; &quot;&quot;, &quot;APOLLO CAREER CENTER&quot;, &quot;&quot;, &quot;&quot;… ## $ CITY &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;ST. MARYS CITY&quot;, &quot;MONROE … ## $ CITY_SCHOOL_DISTRICT &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;ST MARYS CITY SD&quot;, &quot;&quot;, &quot;C… ## $ COUNTY_COURT_DISTRICT &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ CONGRESSIONAL_DISTRICT &lt;int&gt; 4, 4, 4, 8, 11, 2, 11, 16, 2, 14, … ## $ COURT_OF_APPEALS &lt;int&gt; 3, 3, 3, 12, 8, 12, 8, 8, 12, 11, … ## $ EDU_SERVICE_CENTER_DISTRICT &lt;chr&gt; &quot;AUGLAIZE COUNTY ESC&quot;, &quot;ALLEN COUN… ## $ EXEMPTED_VILL_SCHOOL_DISTRICT &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ LIBRARY &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ LOCAL_SCHOOL_DISTRICT &lt;chr&gt; &quot;MINSTER LOCAL SD (AUGLAIZE)&quot;, &quot;SH… ## $ MUNICIPAL_COURT_DISTRICT &lt;chr&gt; &quot;&quot;, &quot;LIMA&quot;, &quot;&quot;, &quot;&quot;, &quot;CLEVELAND&quot;, &quot;… ## $ PRECINCT_NAME &lt;chr&gt; &quot;PRECINCT MINSTER N&quot;, &quot;SHAWNEE H&quot;,… ## $ PRECINCT_CODE &lt;chr&gt; &quot;06AAZ&quot;, &quot;02AFU&quot;, &quot;06AAE&quot;, &quot;09-P-A… ## $ STATE_BOARD_OF_EDUCATION &lt;int&gt; 1, 1, 1, 3, 11, 10, 11, 5, 10, 7, … ## $ STATE_REPRESENTATIVE_DISTRICT &lt;int&gt; 84, 4, 82, 53, 9, 65, 12, 16, 65, … ## $ STATE_SENATE_DISTRICT &lt;int&gt; 12, 12, 1, 4, 21, 14, 25, 24, 14, … ## $ TOWNSHIP &lt;chr&gt; &quot;JACKSON TOWNSHIP&quot;, &quot;Township Shaw… ## $ VILLAGE &lt;chr&gt; &quot;MINSTER VILLAGE&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;,… ## $ WARD &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;ST. MARYS WARD 3&quot;, &quot;&quot;, &quot;C… ## $ `PRIMARY-03/07/2000` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `GENERAL-11/07/2000` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;X&quot;, … ## $ `SPECIAL-05/08/2001` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `GENERAL-11/06/2001` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;… ## $ `PRIMARY-05/07/2002` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `GENERAL-11/05/2002` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;… ## $ `SPECIAL-05/06/2003` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `GENERAL-11/04/2003` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `PRIMARY-03/02/2004` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;D&quot;, &quot;&quot;, &quot;… ## $ `GENERAL-11/02/2004` &lt;chr&gt; &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, … ## $ `SPECIAL-02/08/2005` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X… ## $ `PRIMARY-05/03/2005` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `PRIMARY-09/13/2005` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `GENERAL-11/08/2005` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;… ## $ `SPECIAL-02/07/2006` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `PRIMARY-05/02/2006` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;D&quot;, &quot;&quot;, &quot;… ## $ `GENERAL-11/07/2006` &lt;chr&gt; &quot;X&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;X&quot;,… ## $ `PRIMARY-05/08/2007` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `PRIMARY-09/11/2007` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `GENERAL-11/06/2007` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `PRIMARY-11/06/2007` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `GENERAL-12/11/2007` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `PRIMARY-03/04/2008` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;D&quot;, &quot;D&quot;, … ## $ `PRIMARY-10/14/2008` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `GENERAL-11/04/2008` &lt;chr&gt; &quot;X&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;X&quot;, &quot;X&quot;, &quot;X… ## $ `GENERAL-11/18/2008` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `PRIMARY-05/05/2009` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `PRIMARY-09/08/2009` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `PRIMARY-09/15/2009` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `PRIMARY-09/29/2009` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `GENERAL-11/03/2009` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, … ## $ `PRIMARY-05/04/2010` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `PRIMARY-07/13/2010` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `PRIMARY-09/07/2010` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `GENERAL-11/02/2010` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;X&quot;, &quot;X&quot;, &quot;X&quot;… ## $ `PRIMARY-05/03/2011` &lt;chr&gt; &quot;X&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;… ## $ `PRIMARY-09/13/2011` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `GENERAL-11/08/2011` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;X&quot;, &quot;X&quot;, &quot;&quot;,… ## $ `PRIMARY-03/06/2012` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;D&quot;, &quot;&quot;, &quot;… ## $ `GENERAL-11/06/2012` &lt;chr&gt; &quot;X&quot;, &quot;&quot;, &quot;X&quot;, &quot;X&quot;, &quot;&quot;, &quot;X&quot;, &quot;X&quot;, &quot;… ## $ `PRIMARY-05/07/2013` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;&quot;, &quot;… ## $ `PRIMARY-09/10/2013` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `PRIMARY-10/01/2013` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `GENERAL-11/05/2013` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, … ## $ `PRIMARY-05/06/2014` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;D&quot;, &quot;&quot;, &quot;… ## $ `GENERAL-11/04/2014` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;X&quot;, &quot;X&quot;, &quot;X&quot;… ## $ `PRIMARY-05/05/2015` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `PRIMARY-09/15/2015` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `GENERAL-11/03/2015` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;… ## $ `PRIMARY-03/15/2016` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;D&quot;, &quot;… ## $ `GENERAL-06/07/2016` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `PRIMARY-09/13/2016` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `GENERAL-11/08/2016` &lt;chr&gt; &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;X&quot;, &quot;&quot;, &quot;X&quot;, &quot;X&quot;, &quot;X… ## $ `PRIMARY-05/02/2017` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `PRIMARY-09/12/2017` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;X&quot;, … ## $ `GENERAL-11/07/2017` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;… ## $ `PRIMARY-05/08/2018` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `GENERAL-08/07/2018` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… ## $ `GENERAL-11/06/2018` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;X&quot;, &quot;&quot;, &quot;&quot;, &quot;X&quot;, &quot;X&quot;… ## $ `PRIMARY-05/07/2019` &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;… Nope! They are not tidy. Currently each row represents one voter and the events are on the columns following the format ELECTION TYPE-MM/DD/YYYY. The date of the election should be its own column as should the type (i.e. general, primary, or special). These data need to be converted to a longer format where each row is a unique combination of one voter and election. This means that if an individual voted in five elections, there would be five observations. There are two main steps that need to be taken to tidy up these data. Collect the column headers and their respective values into two new columns: election, and party. Since the column headers contain two variables of interest, namely the election type and election date, the column will be split into two. Usually we would use gather() or pivot_longer() from tidyr. However, these data are quite large and we need to write preformative code. data.table uses data.table::melt() to preform the same operation but is much faster. In this example we specify the id columns. These are the columns that will not be gathered into a new column. We also specify the name of the variable that will be created from the column headers with the variable.name argument. Next, we specfiy the name of the column that will contain the values. sw_gathered &lt;- swvf %&gt;% melt(id = 1:46, variable.name = &quot;election&quot;, value.name = &quot;party&quot;) %&gt;% janitor::clean_names() Preview the results of melt(). The example below uses dplyr::distinct() to identify unique value pairs. # Now we can view the results. The election column can be easily split into two different columns. The election type (i.e. primary or general) and the date of the election. Next, the result column looks like there is a lot of room for cleaning. There are &quot;&quot; where NA should be. distinct(sw_gathered, election, party) ## election party ## 1: PRIMARY-03/07/2000 ## 2: PRIMARY-03/07/2000 D ## 3: PRIMARY-03/07/2000 X ## 4: PRIMARY-03/07/2000 R ## 5: PRIMARY-03/07/2000 L ## --- ## 170: GENERAL-11/06/2018 X ## 171: PRIMARY-05/07/2019 ## 172: PRIMARY-05/07/2019 X ## 173: PRIMARY-05/07/2019 R ## 174: PRIMARY-05/07/2019 D Notice that there are multiple values for party. What are these? # what are the unique values? distinct(sw_gathered, party) ## party ## 1: ## 2: D ## 3: X ## 4: R ## 5: L ## 6: &lt;NA&gt; ## 7: C ## 8: G 7.3.4 Tidying The SOS website has a downloadable data dictionary. The Voter File Layout says: The data dictionary Variable filed name with election type and date of each election. Value for this field indicates how the voter voted in that election. Abbr. Party Name C Constitution Party D Democrat Party E Reform Party G Green Party L Libertarian Party N Natural Law Party R Republican Party S Socialist Party X Voted without declaring party affiliation Blank Indicates that there is no voting record for this voter for this election We can use this to clean up the party field using case_when(). To create two separate columns for the election type and date, we can split on the first -. tidyr::separate() will split the column into two or more columns based on the sep argument. Once the election_date column has been created, we will need to parse it accordingly using lubridate. Since the date column is formatted as MM/DD/YYYY we can use lubridate::mdy() to parse it to class Date. sw_clean &lt;- sw_gathered %&gt;% tidyr::separate(election, into = c(&quot;election_type&quot;, &quot;election_date&quot;), sep = &quot;-&quot;) %&gt;% mutate(election_date = lubridate::mdy(election_date), party = case_when( party == &quot;C&quot; ~ &quot;Constitution&quot;, party == &quot;D&quot; ~ &quot;Democrat&quot;, party == &quot;E&quot; ~ &quot;Reform&quot;, party == &quot;G&quot; ~ &quot;Green&quot;, party == &quot;L&quot; ~ &quot;Libertarian&quot;, party == &quot;N&quot; ~ &quot;Natural Law&quot;, party == &quot;R&quot; ~ &quot;Republican&quot;, party == &quot;S&quot; ~ &quot;Socialist&quot;, party == &quot;X&quot; ~ &quot;Independent&quot; )) head(sw_clean) ## sos_voterid county_number county_id last_name first_name middle_name ## 1 OH0016238254 6 21511 KUETHER BARBARA A ## 2 OH0019414074 2 1010005 GEMLICK JODI LYN ## 3 OH0019419095 6 40055 KITCHEN LESLIE L ## 4 OH0019489283 9 482703 GRACE AMANDA LEIGH ## 5 OH0015384921 18 2044314 CARNER TIFFANY J ## 6 OH0020115764 13 6100757 VAN SCYOC SUSAN L ## suffix date_of_birth registration_date voter_status party_affiliation ## 1 1969-11-15 1998-02-23 ACTIVE ## 2 1972-08-19 2007-01-29 ACTIVE ## 3 1969-12-26 2008-01-09 ACTIVE ## 4 1974-11-09 2008-02-01 ACTIVE ## 5 1971-08-28 2016-05-25 ACTIVE ## 6 1973-08-01 2008-09-18 ACTIVE ## residential_address1 residential_secondary_addr residential_city ## 1 725 OAKWOOD DR MINSTER ## 2 3464 WOODHAVEN LN LIMA ## 3 122 CONCORD AVE ST MARYS ## 4 932 SLEEPY HOLLOW DR MONROE ## 5 13902 BENWOOD AVE CLEVELAND ## 6 1090 S MUSCOVY DR LOVELAND ## residential_state residential_zip residential_zip_plus4 ## 1 OH 45865 NA ## 2 OH 45806 NA ## 3 OH 45885 NA ## 4 OH 45050 NA ## 5 OH 44105 NA ## 6 OH 45140 NA ## residential_country residential_postalcode mailing_address1 ## 1 NA NA ## 2 NA NA ## 3 NA NA ## 4 NA NA ## 5 NA NA ## 6 NA NA ## mailing_secondary_address mailing_city mailing_state mailing_zip ## 1 NA NA ## 2 NA NA ## 3 NA NA ## 4 NA NA ## 5 NA NA ## 6 NA NA ## mailing_zip_plus4 mailing_country mailing_postal_code ## 1 NA ## 2 NA ## 3 NA ## 4 NA ## 5 NA ## 6 NA ## career_center city city_school_district ## 1 ## 2 APOLLO CAREER CENTER ## 3 ST. MARYS CITY ST MARYS CITY SD ## 4 MONROE CITY ## 5 CLEVELAND MUNICIPAL CITY SD ## 6 GREAT OAKS CAREER CAMPUSES ## county_court_district congressional_district court_of_appeals ## 1 NA 4 3 ## 2 NA 4 3 ## 3 NA 4 3 ## 4 NA 8 12 ## 5 NA 11 8 ## 6 NA 2 12 ## edu_service_center_district exempted_vill_school_district library ## 1 AUGLAIZE COUNTY ESC NA ## 2 ALLEN COUNTY ESC NA ## 3 NA ## 4 BUTLER COUNTY ESC NA ## 5 NA ## 6 NA ## local_school_district municipal_court_district ## 1 MINSTER LOCAL SD (AUGLAIZE) ## 2 SHAWNEE LOCAL SD (ALLEN) LIMA ## 3 ## 4 MONROE LOCAL SD (BUTLER) ## 5 CLEVELAND ## 6 ## precinct_name precinct_code state_board_of_education ## 1 PRECINCT MINSTER N 06AAZ 1 ## 2 SHAWNEE H 02AFU 1 ## 3 PRECINCT ST. MARYS 3A 06AAE 1 ## 4 MONROE 2 09-P-AKN 3 ## 5 CLEVELAND-02-Q 18-P-ALJ 11 ## 6 MIAMI TOWNSHIP X 13-P-ACY 10 ## state_representative_district state_senate_district township ## 1 84 12 JACKSON TOWNSHIP ## 2 4 12 Township Shawnee ## 3 82 1 ST MARYS TOWNSHIP ## 4 53 4 LEMON TOWNSHIP ## 5 9 21 ## 6 65 14 MIAMI TWP ## village ward election_type election_date party ## 1 MINSTER VILLAGE PRIMARY 2000-03-07 &lt;NA&gt; ## 2 PRIMARY 2000-03-07 &lt;NA&gt; ## 3 ST. MARYS WARD 3 PRIMARY 2000-03-07 &lt;NA&gt; ## 4 PRIMARY 2000-03-07 &lt;NA&gt; ## 5 CLEVELAND WARD 2 PRIMARY 2000-03-07 &lt;NA&gt; ## 6 PRIMARY 2000-03-07 &lt;NA&gt; 7.3.5 Creating targets One thing that you will need to do is identify your potential voter base. These voters are sometimes referred to as your “targets” or your voter “universe”. Each voter is a unique culmination of experience, opinions, and biases. As such, not every person will be willing to vote for your candidate or maybe to even vote at all. Some people are habitual voters who vote in every election and always along party lines. Others may only sometimes vote in a general election. And others might not vote consistently along party lines. Due to the never ending complexities that are peoples’ preferences and persuasions it is important to break the pool of potential voters down into smaller groups which I will refer to as tiers. We will break our voters into three distinct tiers. These categorizations are rather crude. Work with your state leadership team to determine the best way to segment your voter base. Tier 1. Base voters - registered Democrats who have voted Democrat in a primary Tier 2. Motivation - are not registered with a party but have voted Democrat in a primary Tier 3. Persuasion - folks that have voted Democrat in a priimary but aren’t registered as such To begin this process, we want to identify everyone who has voted Democrat in a primary. We will filter sw_clean to these criteria. Then we will count the number of times each voter has voted for a Democrat. This will then be joined back to the original data frame so we can identify those people who have voted Democrat even if it conflicts with their party registration. # One thing that you will need to do is to identify your target base voters. These will most likely be those who have voted Democrat in previous primaries. Then we will compare those people with their registered party. primary_dems &lt;- sw_clean %&gt;% filter(election_type == &quot;PRIMARY&quot;, party == &quot;Democrat&quot;) %&gt;% count(sos_voterid, party) head(primary_dems) ## # A tibble: 6 x 3 ## sos_voterid party n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 OH0010002426 Democrat 1 ## 2 OH0010004408 Democrat 1 ## 3 OH0010012148 Democrat 1 ## 4 OH0010012441 Democrat 3 ## 5 OH0010013144 Democrat 1 ## 6 OH0010015404 Democrat 1 Now that we have a table of everyone who has voted for a Democrat in a primary, we need to join this back onto the original voter file. The motivation for this is that by joining back onto the orginal table we can then use some of the other information that it provides such as party affiliation and birth year, among others. # join these back to the original voter file to get additional information potential_targets &lt;- inner_join(primary_dems, swvf, by = c(&quot;sos_voterid&quot; = &quot;SOS_VOTERID&quot;)) %&gt;% janitor::clean_names() %&gt;% select(sos_voterid, party_affiliation, precinct_name, date_of_birth, registration_date, party, n) %&gt;% mutate(age = as.integer((Sys.Date() - lubridate::ymd(date_of_birth)) / 365)) select(potential_targets, sos_voterid, precinct_name, party_affiliation, age, n) %&gt;% arrange(-n) %&gt;% head() ## # A tibble: 6 x 5 ## sos_voterid precinct_name party_affiliation age n ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 OH0010322183 PRECINCT ASHTABULA 2-A D 68 14 ## 2 OH0015532776 ATHENS 3-4 D 63 14 ## 3 OH0010329359 PRECINCT ASHTABULA 5-A D 56 13 ## 4 OH0014653051 EAST CLEVELAND-03-C D 79 13 ## 5 OH0014799002 PARMA-04-A D 60 13 ## 6 OH0014805561 PARMA-05-A D 65 13 Let’s create some cross tables to identify how many times people of each party voted for a Demorat in a primary. # generate some cross-tabs. Everyone loves cross tabs. count(potential_targets, party_affiliation, party) %&gt;% mutate(prop = round(n / sum(n), 2)) ## # A tibble: 4 x 4 ## party_affiliation party n prop ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 &quot;&quot; Democrat 1093 0.3 ## 2 D Democrat 1828 0.51 ## 3 G Democrat 4 0 ## 4 R Democrat 663 0.18 What is most telling from this table is that 30% of individuals who voted for a Democrat in the primary have no party affiliation. Now that we have a data frame with voter IDs and their registered party. We can begin segmenting this group based on the afore mentioned definitions. This will be done with a basic case_when() statement. # Tier 1 base dems will be those that are registered dem and have voted dem # we will tier our targets # Tier 2 will be our motivation group. # Those that aren&#39;t registered with a party, but have voted Dem # Tier 3 will be our persuasion group. # These are the folks that have voted Dem but aren&#39;t registered as such. # export thiws and upload to VAN or other management software. targets &lt;- potential_targets %&gt;% mutate(tier = case_when( party_affiliation == &quot;D&quot; ~ 1, party_affiliation == &quot;&quot; ~ 2, !party_affiliation %in% c(&quot;&quot;, &quot;D&quot;) ~ 3 )) Now select voter ID and tier, write as a csv, and bulk upload into VAN! ## # A tibble: 3 x 5 ## tier med_age n_primaries tier_size p ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 59 8071 1828 0.700 ## 2 2 56 2026 1093 0.176 ## 3 3 62 1436 667 0.125 "]
]
